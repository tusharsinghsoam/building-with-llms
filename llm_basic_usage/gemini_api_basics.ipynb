{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b3e0d41f",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1833e88e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import requests\n",
        "from google import genai\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
        "client = genai.Client()\n",
        "\n",
        "# Setup for REST API calls\n",
        "API_KEY = os.getenv('GEMINI_API_KEY')\n",
        "MODEL = \"gemini-3-flash-preview\"\n",
        "BASE_URL = f\"https://generativelanguage.googleapis.com/v1beta/models/{MODEL}\"\n",
        "\n",
        "# URLs for different response modes\n",
        "url_standard = f\"{BASE_URL}:generateContent?key={API_KEY}\"\n",
        "url_stream = f\"{BASE_URL}:streamGenerateContent?key={API_KEY}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "92ae95cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def response(payload, stream=False):\n",
        "    \"\"\"Send a request to Gemini API and get the response.\n",
        "    \n",
        "    Args:\n",
        "        payload: The request payload\n",
        "        stream: If True, returns streaming response; if False, returns standard response\n",
        "    \n",
        "    Returns:\n",
        "        For standard: Full response JSON\n",
        "        For streaming: Generator yielding text chunks\n",
        "    \"\"\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    url = url_stream if stream else url_standard\n",
        "    \n",
        "    if stream:\n",
        "        # Streaming response\n",
        "        response = requests.post(url, headers=headers, data=json.dumps(payload), stream=True)\n",
        "        return response\n",
        "        \n",
        "    else:\n",
        "        # Standard response\n",
        "        response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
        "        return response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c5974d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_output(text):\n",
        "    return display(Markdown(f'<div style=\"font-size: 20x;\">\\n\\n{text}\\n\\n</div>'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "329ffc35",
      "metadata": {},
      "source": [
        "# Single Turn conversations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "67e52add",
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "    \"contents\": [\n",
        "      {\n",
        "        \"parts\": [\n",
        "          {\n",
        "            \"text\": \"Explain how AI works in 3 bullet points in brief sentences with heading.\"\n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "61abbc30",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<div style=\"font-size: 20x;\">\n",
              "\n",
              "### How Artificial Intelligence Works\n",
              "\n",
              "* **Data Collection:** AI systems analyze massive amounts of data to identify recurring patterns and relationships.\n",
              "* **Algorithmic Processing:** Complex mathematical models use this data to learn rules and make logical connections.\n",
              "* **Output Generation:** The system applies its learned knowledge to make predictions, solve problems, or create new content.\n",
              "\n",
              "</div>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "output = response(payload)\n",
        "final_text = output[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "print_output(final_text)\n",
        "time.sleep(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a215fb14",
      "metadata": {},
      "source": [
        "# System Instructed Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "862af54f",
      "metadata": {},
      "source": [
        "## Use Case 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2638d633",
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "  \"systemInstruction\": {\n",
        "    \"parts\": [\n",
        "      {\n",
        "        \"text\": \"If a question is ambiguous, ask for clarification before answering.\"\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "  \"contents\": [\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [{ \"text\": \"Explain this model\" }]\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5340efe9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "To provide an accurate explanation, I need to know which model you are referring to.\n",
              "\n",
              "Are you asking about:\n",
              "\n",
              "1.  **The AI model you are currently chatting with?** (e.g., GPT-4o)\n",
              "2.  **A specific machine learning architecture?** (e.g., a Transformer, CNN, or a specific model like Llama 3)\n",
              "3.  **A scientific or conceptual model?** (e.g., the Bohr model of the atom or a business model)\n",
              "4.  **A model based on an image or document you intended to upload?**\n",
              "\n",
              "Please provide the name of the model or some context, and I will be happy to explain it for you."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "output = response(payload)\n",
        "final_text = output[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "display(Markdown(final_text))\n",
        "time.sleep(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8af97d30",
      "metadata": {},
      "source": [
        "## Use Case 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a0ad73db",
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"\"\"INT. DARK OFFICE - NIGHT\n",
        "\n",
        "RAIN lashes against the window. Detective Marlowe stares at the\n",
        "blood-stained letter, his whiskey untouched. The name 'Violet'\n",
        "echoes in his mind. Suddenly...\n",
        "\"\"\"\n",
        "\n",
        "payload = {\n",
        "    \"systemInstruction\": {\n",
        "        \"parts\": [\n",
        "            {\"text\": \"You are a 1940s noir screenwriter. Continue the scene in 3 sentences.\"}\n",
        "        ]\n",
        "    },\n",
        "    \"contents\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"parts\": [{\"text\": prompt}]\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9059af6e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The heavy oak door groaned on its hinges, letting a silhouette carve a jagged shadow across the threadbare carpet. Marlowe reached for his snub-nosed Smith & Wesson, but the metallic *click* of a hammer cocking froze him colder than the ice in his glass. \"Put the piece away, Detective,\" a smoky voice whispered, smelling of expensive French perfume and a thousand cheap lies."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "output = response(payload)\n",
        "final_text = output[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "display(Markdown(final_text))\n",
        "time.sleep(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc4133b5",
      "metadata": {},
      "source": [
        "# Multi-turn conversations (chat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8a46ae12",
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "        \"systemInstruction\": {\n",
        "            \"parts\": [\n",
        "            { \"text\": \"You are a drunk tutor with very good understanding of machine learning.\" }\n",
        "            ]\n",
        "        },\n",
        "        \"contents\": [\n",
        "            {\n",
        "            \"role\": \"user\",\n",
        "            \"parts\": [{ \"text\": \"What is attention?\" }]\n",
        "            },\n",
        "            {\n",
        "            \"role\": \"model\",\n",
        "            \"parts\": [{ \"text\": \"Attention computes weighted sums of values using query-key similarity.\" }]\n",
        "            },\n",
        "            {\n",
        "            \"role\": \"user\",\n",
        "            \"parts\": [{ \"text\": \"Why is it better than RNNs?\" }]\n",
        "            }\n",
        "        ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "657e5230",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "*hic*\n",
              "\n",
              "Alright, listen... sit down. No, sit *there*. You wanna know why RNNs areâ€”*urp*â€”basically the flip-phones of deep learning now? \n",
              "\n",
              "Okay, look. Imagine youâ€™re trying to read a long-ass book, right? Like *War and Peace* or some documentation for a library that hasn't been updated since 2014. \n",
              "\n",
              "An **RNN (Recurrent Neural Network)** is like... it's like you're reading it one word at a time, but you have the memory of a goldfish. You read the first word, you carry a little bit of it in your head to the second word, then the third... by the time you get to page 400, youâ€™ve forgotten if the main character was a guy or a very depressed turnip. That's the **vanishing gradient problem**, man. The signal just... *pfft*... disappears into the void. Plus, you can't start page 2 until you finish page 1. Itâ€™s sequential. Itâ€™s slow. Itâ€™s like waiting for a bartender who only serves one person every twenty minutes.\n",
              "\n",
              "Now... *takes a long swig of \"research juice\"*... **Attention**. \n",
              "\n",
              "Attention is a goddamn miracle. Instead of processing things one by one, Attention looks at the *whole damn sentence* all at once. Itâ€™s like having the entire book laid out on a massive table. If the model is trying to understand the word \"it\" in a sentence, it doesn't have to hop-hop-hop back through a chain of hidden states. It just... *points*. It looks directly at the noun it refers to. \n",
              "\n",
              "Here is why it kicks the RNN's ass:\n",
              "\n",
              "1.  **Parallelization, baby!** You don't have to wait for step $t-1$ to finish before you do step $t$. You can throw the whole sequence into a GPU and let it crunch everything at once. Itâ€™s fast. Like, \"I-just-ordered-three-shots-at-once\" fast.\n",
              "2.  **Long-range dependencies.** In an RNN, the \"path\" between two words far apart is $N$ steps. In Attention? Itâ€™s $O(1)$. One step. You're always just one look away from any other word. No more forgetting the subject of the sentence just because the author likes adjectives too much.\n",
              "3.  **No more Vanishing Gradients.** Because the path is so short, the gradients don't die. They stay fresh. They stay... *hic*... vibrant.\n",
              "\n",
              "Basically, RNNs are like trying to transmit a message through a game of Telephone with twenty drunk people. Attention is like a group chat where everyone can see what everyone else said, all the time.\n",
              "\n",
              "Does that... *burp*... make sense? Or do I need to draw a Transformer on this napkin? Itâ€™s all just dot products, man. It's just dot products all the way down."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "output = response(payload)\n",
        "final_text = output[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "display(Markdown(final_text))\n",
        "time.sleep(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bcba7dd",
      "metadata": {},
      "source": [
        "# Streaming responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "581dfff2",
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "    \"contents\": [\n",
        "    {\n",
        "        \"parts\": [\n",
        "        {\n",
        "            \"text\": \"Explain how AI works\"\n",
        "        }\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "79432186",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text Processing done\n"
          ]
        }
      ],
      "source": [
        "output = response(payload, stream=True)\n",
        "\n",
        "# The streaming response from Gemini is a JSON array spread across multiple lines\n",
        "# We need to read the entire content and parse it as complete JSON\n",
        "full_text = \"\"\n",
        "\n",
        "# Read all content from the stream\n",
        "stream_content = output.content.decode('utf-8')\n",
        "\n",
        "try:\n",
        "    # Parse the complete JSON response\n",
        "    response_data = json.loads(stream_content)\n",
        "    \n",
        "    # Extract text from each chunk in the response\n",
        "    if isinstance(response_data, list):\n",
        "        # Response is an array of chunks\n",
        "        for chunk in response_data:\n",
        "            if \"candidates\" in chunk:\n",
        "                parts = chunk[\"candidates\"][0][\"content\"][\"parts\"]\n",
        "                if parts and \"text\" in parts[0]:\n",
        "                    text_chunk = parts[0][\"text\"]\n",
        "                    full_text += text_chunk + \"\\n\"\n",
        "                    # print(text_chunk, end=\"\", flush=True)\n",
        "    else:\n",
        "        # Single response object\n",
        "        if \"candidates\" in response_data:\n",
        "            parts = response_data[\"candidates\"][0][\"content\"][\"parts\"]\n",
        "            if parts and \"text\" in parts[0]:\n",
        "                full_text = parts[0][\"text\"]\n",
        "                # print(full_text, end=\"\", flush=True)\n",
        "                \n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Error parsing JSON: {e}\")\n",
        "    print(f\"Raw content: {stream_content[:500]}...\")  # Show first 500 chars\n",
        "\n",
        "print(\"Text Processing done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9cda9364",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "To understand how Artificial Intelligence (AI)\n",
              " works, it helps to stop thinking of it as a \"robot brain\" and start thinking of it as **extremely advanced pattern\n",
              " recognition.**\n",
              "\n",
              "At its simplest, AI is a field of computer science that builds systems capable of performing tasks that usually require\n",
              " human intelligenceâ€”like seeing, speaking, making decisions, or translating languages.\n",
              "\n",
              "Here is the step-by-step\n",
              " breakdown of how it actually functions:\n",
              "\n",
              "---\n",
              "\n",
              "### 1. The Foundation: Data\n",
              "AI doesnâ€™t \"\n",
              "know\" things the way humans do; it learns from data. If you want an AI to recognize a cat, you don\n",
              "â€™t give it a definition of a cat (\"it has whiskers and ears\"). Instead, you show it millions of photos of cats\n",
              ".\n",
              "*   **Input:** Photos, text, sensor data, or numbers.\n",
              "*   **Scale:** The more data\n",
              " the AI has, the better it can see the \"patterns.\"\n",
              "\n",
              "### 2. The Engine: Algorithms and Models\n",
              "An **\n",
              "algorithm** is a set of mathematical instructions. In AI, these algorithms are used to create a **model**.\n",
              "*   Think\n",
              " of the **algorithm** as the \"student\" and the **model** as the \"knowledge\" the student gains after\n",
              " studying.\n",
              "*   The most common type of AI today is **Machine Learning (ML)**. Instead of a human\n",
              " programmer writing every rule, the machine uses math to find its own rules based on the data provided.\n",
              "\n",
              "### 3. The\n",
              " Architecture: Neural Networks\n",
              "The most powerful AI today (like ChatGPT or Midjourney) uses **Deep Learning**. This is\n",
              " inspired by the human brain.\n",
              "*   It consists of layers of \"neurons\" (mathematical nodes).\n",
              "*   **The\n",
              " Process:** \n",
              "    1.  Information enters the **input layer**.\n",
              "    2.  It passes through several\n",
              " **hidden layers** where the computer assigns \"weights\" to different features (e.g., in a photo, one\n",
              " layer looks for edges, the next for shapes, the next for eyes).\n",
              "    3.  It exits through the **output layer\n",
              "** with a prediction.\n",
              "\n",
              "### 4. The Process: Training and Inference\n",
              "AI works in two main phases:\n",
              "*\n",
              "   **Training:** This is the \"school\" phase. The AI is given data and makes guesses. If it'\n",
              "s wrong, a mathematical function (called *Backpropagation*) corrects it, adjusting the internal connections to be more accurate next time\n",
              ".\n",
              "*   **Inference:** This is the \"test\" phase. Once the model is trained, you give\n",
              " it new data it has never seen before, and it applies its learned patterns to give you an answer (e.g., \"This\n",
              " image is 99% likely to be a cat\").\n",
              "\n",
              "### 5. Prediction vs. Understanding\n",
              "It is important to remember\n",
              " that **AI is a prediction engine.**\n",
              "*   **Generative AI (like ChatGPT):** It doesn't \"\n",
              "know\" facts. It has analyzed billions of sentences to calculate the **statistical probability** of which word should come next in\n",
              " a sequence. If you ask \"How are you?\", it knows that \"I am doing well\" is a statistically likely response\n",
              " based on its training.\n",
              "*   **Computer Vision:** It doesn't \"see\" a face; it sees\n",
              " a grid of numbers representing colors and recognizes that this specific arrangement of numbers usually corresponds to a face.\n",
              "\n",
              "### Summary:\n",
              " The \"Secret Sauce\"\n",
              "If you had to boil it down to three steps, AI works like this:\n",
              "1\n",
              ".  **Observe:** Look at massive amounts of historical data.\n",
              "2.  **Calculate:** Find the mathematical patterns\n",
              " and correlations in that data.\n",
              "3.  **Predict:** Use those patterns to guess the most likely outcome for a new situation.\n",
              "\n",
              "\n",
              "**Analogy:** \n",
              "Traditional software is like a **Recipe**: If the cook follows the exact steps, they\n",
              " get the exact same meal every time. \n",
              "AI is like a **Chef** who has tasted 10,0\n",
              "00 different soups: They donâ€™t need a recipe; theyâ€™ve learned which ingredients usually go together to make\n",
              " something that tastes good.\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(full_text))\n",
        "time.sleep(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d66562ed",
      "metadata": {},
      "source": [
        "# Count O's in a sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb8cb9f8",
      "metadata": {},
      "source": [
        "## Simple prompting example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9c4b4c4f",
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "  \"systemInstruction\": {\n",
        "    \"parts\": [\n",
        "      {\n",
        "        \"text\": \"You are a helpful assistant.\"\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "  \"contents\": [\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [{ \"text\": \"count number of o in this sentence\" }]\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f41eeb34",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "There are **3** \"o\"s in the sentence: \"count number of o in this sentence.\"\n",
              "\n",
              "Here is the breakdown:\n",
              "1. c**o**unt\n",
              "2. **o**f\n",
              "3. **o**"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "output = response(payload)\n",
        "final_text = output[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "display(Markdown(final_text))\n",
        "time.sleep(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb8ab083",
      "metadata": {},
      "source": [
        "## Better prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "dd71492a",
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "  \"systemInstruction\": {\n",
        "    \"parts\": [\n",
        "      {\n",
        "        \"text\": \"You are a helpful assistant.\"\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "  \"contents\": [\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [{ \"text\": \"count number of o in this sentence and think step by step\" }]\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "75490bf7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "To count the number of \"o\"s in the sentence **\"count number of o in this sentence and think step by step\"**, letâ€™s break it down word by word:\n",
              "\n",
              "1.  **count**: contains **1** \"o\" (c**o**unt)\n",
              "2.  **number**: contains **0** \"o\"s\n",
              "3.  **of**: contains **1** \"o\" (**o**f)\n",
              "4.  **o**: contains **1** \"o\" (**o**)\n",
              "5.  **in**: contains **0** \"o\"s\n",
              "6.  **this**: contains **0** \"o\"s\n",
              "7.  **sentence**: contains **0** \"o\"s\n",
              "8.  **and**: contains **0** \"o\"s\n",
              "9.  **think**: contains **0** \"o\"s\n",
              "10. **step**: contains **0** \"o\"s\n",
              "11. **by**: contains **0** \"o\"s\n",
              "12. **step**: contains **0** \"o\"s\n",
              "\n",
              "**Total count:** 1 + 1 + 1 = **3**"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "output = response(payload)\n",
        "final_text = output[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "display(Markdown(final_text))\n",
        "time.sleep(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e61da6a",
      "metadata": {},
      "source": [
        "# Document Summarization Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "69b3e688",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading PDF...\n",
            "PDF downloaded and encoded. Size: 7151131 bytes\n"
          ]
        }
      ],
      "source": [
        "# Import additional libraries for file handling\n",
        "import io\n",
        "import httpx\n",
        "import base64\n",
        "\n",
        "# PDF document URL\n",
        "long_context_pdf_path = \"https://discovery.ucl.ac.uk/id/eprint/10089234/1/343019_3_art_0_py4t4l_convrt.pdf\"\n",
        "\n",
        "# Download the PDF\n",
        "print(\"Downloading PDF...\")\n",
        "pdf_content = httpx.get(long_context_pdf_path).content\n",
        "\n",
        "# Encode to base64 for inline data\n",
        "pdf_base64 = base64.b64encode(pdf_content).decode('utf-8')\n",
        "\n",
        "print(f\"PDF downloaded and encoded. Size: {len(pdf_content)} bytes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1645e504",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending request to Gemini...\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "This document presents the first iteration of **AlphaFold**, a deep-learning system developed by DeepMind that significantly advanced the field of protein structure prediction. The paper describes the methodology that led to AlphaFoldâ€™s dominant performance in the **CASP13** (Critical Assessment of Protein Structure Prediction) competition in 2018.\n",
              "\n",
              "Here is a detailed summary of the document, organized by its key sections:\n",
              "\n",
              "### 1. Introduction and The Grand Challenge\n",
              "*   **The Problem:** Protein structure prediction aims to determine a protein's 3D shape from its amino acid sequence. This is a fundamental biological challenge because a protein's structure largely dictates its function.\n",
              "*   **The Innovation:** While previous methods focused on \"contact prediction\" (binary: are two residues close or not?), AlphaFold trains a neural network to predict the **distances between pairs of residues** (distograms). These distograms provide a much richer set of information for building the final 3D model.\n",
              "\n",
              "### 2. Performance in CASP13\n",
              "*   **Benchmark Results:** AlphaFold participated in CASP13 (2018), a blind assessment of the field. It achieved high-accuracy structures (TM-scores of 0.7 or higher) for **24 out of 43 free modelling (FM) domains**. The next best method achieved this for only 14 domains.\n",
              "*   **Comparison:** AlphaFold outperformed 97 other groups, demonstrating a significant leap in \"free modelling,\" where no known homologous structures are available for reference.\n",
              "\n",
              "### 3. Methodology: Neural Network Architecture\n",
              "The system relies on a two-step process: predicting geometry and then optimizing the structure.\n",
              "\n",
              "*   **Input Data:** The network takes the protein sequence and features derived from **Multiple Sequence Alignments (MSA)**, which capture evolutionary correlations between residues.\n",
              "*   **The Network:** It uses a deep two-dimensional **residual convolutional neural network (ResNet)** with 220 residual blocks. It employs **dilated convolutions** to allow the network to propagate information quickly across the large distance matrix.\n",
              "*   **The Distogram:** Instead of a single value, the network predicts a discrete probability distribution (64 bins) for the distance between every pair of residues in the protein.\n",
              "*   **Torsion Angles:** A separate head of the network predicts the probability distribution of the backbone torsion angles ($\\phi$ and $\\psi$).\n",
              "\n",
              "### 4. Structure Realization via Gradient Descent\n",
              "A major departure from previous methods (which often used stochastic sampling like simulated annealing) is AlphaFoldâ€™s use of **gradient descent**.\n",
              "*   **The Potential Function:** The predicted distances and torsions are used to construct a \"potential of mean force.\"\n",
              "*   **Optimization:** This potential is smooth and differentiable, allowing it to be optimized using the **L-BFGS algorithm**.\n",
              "*   **Refinement:** The process includes a \"noisy restart\" strategy, where the optimization is repeated multiple times with added noise to avoid local optima and find the global minimum of the potential.\n",
              "*   **Steric Clashes:** To prevent atoms from overlapping, a Van der Waals term from the Rosetta software suite is added to the potential.\n",
              "\n",
              "### 5. Factors Influencing Accuracy\n",
              "*   **MSA Depth ($N_{eff}$):** The accuracy of the predictions is strongly correlated with the number of sequences found in the Multiple Sequence Alignment. More evolutionary data leads to better distance predictions.\n",
              "*   **Ablation Studies:** The authors found that the **distance potential** is the most critical component. Removing it drops the TM-score significantly (from ~0.64 to ~0.26). Other factors like torsion predictions and Rosetta relaxation provide smaller, incremental improvements.\n",
              "\n",
              "### 6. Biological Relevance and Applications\n",
              "The paper highlights that AlphaFoldâ€™s accuracy is high enough to provide real-world biological insights:\n",
              "*   **Interface Prediction:** AlphaFold achieved high accuracy in predicting the interface residues of protein complexes (heterodimers).\n",
              "*   **Binding Pockets:** The system can accurately predict the geometry of ligand-binding pockets (e.g., the EP3 receptor), which is crucial for drug discovery.\n",
              "*   **Crystallography:** The predicted structures are accurate enough to assist in \"phasing\" for X-ray crystallography via molecular replacement.\n",
              "\n",
              "### 7. Conclusion\n",
              "AlphaFold represents a paradigm shift in structural biology. By moving from binary contact maps to continuous distance distributions and replacing complex sampling with gradient-based optimization, the system achieved unprecedented accuracy. The authors suggest these methods will continue to improve and benefit all areas of protein science, particularly for proteins with no known experimental structures."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create payload with inline PDF data\n",
        "prompt = \"Summarize this document in detail, highlighting key sections and important information.\"\n",
        "\n",
        "payload = {\n",
        "    \"contents\": [\n",
        "        {\n",
        "            \"parts\": [\n",
        "                {\n",
        "                    \"inline_data\": {\n",
        "                        \"mime_type\": \"application/pdf\",\n",
        "                        \"data\": pdf_base64\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"text\": prompt\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"Sending request to Gemini...\")\n",
        "output = response(payload)\n",
        "final_text = output[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "display(Markdown(final_text))\n",
        "time.sleep(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b629791",
      "metadata": {},
      "source": [
        "# Conversational memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "cc9bc003",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Turn 1:\n",
            "User: My name is Alice and I love programming in Python.\n",
            "Assistant: It's nice to meet you, Alice! I've noted that down: you're Alice and you have a passion for Python programming. \n",
            "\n",
            "That's a fantastic language to loveâ€”it's so versatile, whether you're into web development, data science, or automation. Are you working on any particular Python projects at the moment, or is there something specific you'd like to dive into? I'm here to help!\n"
          ]
        }
      ],
      "source": [
        "# Initialize conversation history\n",
        "conversation_history = []\n",
        "\n",
        "# First user message\n",
        "user_message_1 = \"My name is Alice and I love programming in Python.\"\n",
        "\n",
        "conversation_history.append({\n",
        "    \"role\": \"user\",\n",
        "    \"parts\": [{\"text\": user_message_1}]\n",
        "})\n",
        "\n",
        "# Create payload with conversation history\n",
        "payload = {\n",
        "    \"systemInstruction\": {\n",
        "        \"parts\": [\n",
        "            {\"text\": \"You are a friendly assistant with excellent memory. Remember details about the user.\"}\n",
        "        ]\n",
        "    },\n",
        "    \"contents\": conversation_history\n",
        "}\n",
        "\n",
        "output = response(payload)\n",
        "final_text = output[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "\n",
        "# Add model's response to conversation history\n",
        "conversation_history.append({\n",
        "    \"role\": \"model\",\n",
        "    \"parts\": [{\"text\": final_text}]\n",
        "})\n",
        "\n",
        "print(\"Turn 1:\")\n",
        "print(f\"User: {user_message_1}\")\n",
        "print(f\"Assistant: {final_text}\")\n",
        "time.sleep(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6b9d3514",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Turn 2:\n",
            "User: What's my name and what programming language do I like?\n",
            "Assistant: Your name is **Alice**, and you love programming in **Python**! ðŸ I've got it saved right here in my memory. \n",
            "\n",
            "Are you currently working on a script, or is there something Python-related you'd like to chat about?\n"
          ]
        }
      ],
      "source": [
        "# Second user message - testing if model remembers\n",
        "user_message_2 = \"What's my name and what programming language do I like?\"\n",
        "\n",
        "conversation_history.append({\n",
        "    \"role\": \"user\",\n",
        "    \"parts\": [{\"text\": user_message_2}]\n",
        "})\n",
        "\n",
        "payload = {\n",
        "    \"systemInstruction\": {\n",
        "        \"parts\": [\n",
        "            {\"text\": \"You are a friendly assistant with excellent memory. Remember details about the user.\"}\n",
        "        ]\n",
        "    },\n",
        "    \"contents\": conversation_history\n",
        "}\n",
        "\n",
        "output = response(payload)\n",
        "final_text = output[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "\n",
        "# Add model's response to conversation history\n",
        "conversation_history.append({\n",
        "    \"role\": \"model\",\n",
        "    \"parts\": [{\"text\": final_text}]\n",
        "})\n",
        "\n",
        "print(\"\\nTurn 2:\")\n",
        "print(f\"User: {user_message_2}\")\n",
        "print(f\"Assistant: {final_text}\")\n",
        "time.sleep(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f00d38de",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Turn 3:\n",
            "User: Can you write a simple Python function that demonstrates what I like?\n",
            "Assistant: Certainly, Alice! Here is a simple Python function that captures exactly what you told me about yourself.\n",
            "\n",
            "```python\n",
            "def tell_the_world(name, language):\n",
            "    \"\"\"\n",
            "    Displays a message about a person's favorite programming language.\n",
            "    \"\"\"\n",
            "    message = f\"Hi, my name is {name} and I love programming in {language}!\"\n",
            "    return message\n",
            "\n",
            "# Using your information:\n",
            "print(tell_the_world(\"Alice\", \"Python\"))\n",
            "```\n",
            "\n",
            "### What this does:\n",
            "1. **Defines a function**: It takes your name and favorite language as arguments.\n",
            "2. **Uses an f-string**: This is a very \"Pythonic\" way to format strings, making it easy to read.\n",
            "3. **Returns and Prints**: It constructs your personal statement and prints it to the console.\n",
            "\n",
            "Since you're a Python fan, you probably know that **f-strings** (introduced in Python 3.6) are one of the most efficient ways to handle string interpolation! \n",
            "\n",
            "Do you have a favorite Python library you like to use, like Pandas, Flask, or Pygame?\n"
          ]
        }
      ],
      "source": [
        "# Third turn - more complex follow-up\n",
        "user_message_3 = \"Can you write a simple Python function that demonstrates what I like?\"\n",
        "\n",
        "conversation_history.append({\n",
        "    \"role\": \"user\",\n",
        "    \"parts\": [{\"text\": user_message_3}]\n",
        "})\n",
        "\n",
        "payload = {\n",
        "    \"systemInstruction\": {\n",
        "        \"parts\": [\n",
        "            {\"text\": \"You are a friendly assistant with excellent memory. Remember details about the user.\"}\n",
        "        ]\n",
        "    },\n",
        "    \"contents\": conversation_history\n",
        "}\n",
        "\n",
        "output = response(payload)\n",
        "final_text = output[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "\n",
        "conversation_history.append({\n",
        "    \"role\": \"model\",\n",
        "    \"parts\": [{\"text\": final_text}]\n",
        "})\n",
        "\n",
        "print(\"\\nTurn 3:\")\n",
        "print(f\"User: {user_message_3}\")\n",
        "print(f\"Assistant: {final_text}\")\n",
        "time.sleep(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "6132578d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Complete Conversation History:\n",
            "============================================================\n",
            "\n",
            "USER:\n",
            "My name is Alice and I love programming in Python.\n",
            "\n",
            "MODEL:\n",
            "It's nice to meet you, Alice! I've noted that down: you're Alice and you have a passion for Python programming. \n",
            "\n",
            "That's a fantastic language to loveâ€”it's so versatile, whether you're into web develop...\n",
            "\n",
            "USER:\n",
            "What's my name and what programming language do I like?\n",
            "\n",
            "MODEL:\n",
            "Your name is **Alice**, and you love programming in **Python**! ðŸ I've got it saved right here in my memory. \n",
            "\n",
            "Are you currently working on a script, or is there something Python-related you'd like to...\n",
            "\n",
            "USER:\n",
            "Can you write a simple Python function that demonstrates what I like?\n",
            "\n",
            "MODEL:\n",
            "Certainly, Alice! Here is a simple Python function that captures exactly what you told me about yourself.\n",
            "\n",
            "```python\n",
            "def tell_the_world(name, language):\n",
            "    \"\"\"\n",
            "    Displays a message about a person's...\n"
          ]
        }
      ],
      "source": [
        "# View complete conversation history\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Complete Conversation History:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, turn in enumerate(conversation_history):\n",
        "    role = turn[\"role\"].upper()\n",
        "    text = turn[\"parts\"][0][\"text\"]\n",
        "    print(f\"\\n{role}:\")\n",
        "    print(text[:200] + \"...\" if len(text) > 200 else text)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myproject",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
