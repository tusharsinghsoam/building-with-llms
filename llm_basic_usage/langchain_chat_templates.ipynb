{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c193fd3",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76188aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numexpr\n",
    "import time\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, FewShotPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.example_selectors import LengthBasedExampleSelector\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2819e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_text(text):\n",
    "    return display(Markdown(f'<div style=\"font-size: 17px;\">\\n\\n{text}\\n\\n</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc4012",
   "metadata": {},
   "source": [
    "# LLM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98cc6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use HuggingFaceEndpoint - automatic routing based on availability\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=300,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "chat_llm = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bed7c1e",
   "metadata": {},
   "source": [
    "# Langchain Quick Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cb5f59",
   "metadata": {},
   "source": [
    "## Asking a simple question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725fa7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "The New Orleans Saints won Super Bowl XLIV (44) in the 2010 season. They defeated the Indianapolis Colts with a score of 31-17.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build prompt template\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "# we chain together the prompt -> LLM with LCEL (more on this later)\n",
    "llm_chain = prompt | chat_llm\n",
    "\n",
    "question = \"Which NFL team won the Super Bowl in the 2010 season?\"\n",
    "\n",
    "text = (llm_chain.invoke(question))\n",
    "time.sleep(3)\n",
    "print_text(text.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e354216",
   "metadata": {},
   "source": [
    "## Asking multiple questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0475e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = [\n",
    "    {'question': \"Which NFL team won the Super Bowl in the 2010 season?\"},\n",
    "    {'question': \"If I am 6 ft 4 inches, how tall am I in centimeters?\"},\n",
    "    {'question': \"Who was the 12th person on the moon?\"},\n",
    "    {'question': \"How many eyes does a blade of grass have?\"}\n",
    "]\n",
    "\n",
    "res = llm_chain.batch(qs)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "096f6bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "====================================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "QUESTION: Which NFL team won the Super Bowl in the 2010 season?\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "RESPONSE: The New Orleans Saints won the Super Bowl in the 2009 season, not the 2010 season. However, the Green Bay Packers won the Super Bowl in the 2010 season.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "====================================================================================================\n",
       "\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "====================================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "QUESTION: If I am 6 ft 4 inches, how tall am I in centimeters?\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "RESPONSE: To convert feet and inches to centimeters, we need to perform the following conversions:\n",
       "\n",
       "1 foot = 30.48 centimeters\n",
       "1 inch = 2.54 centimeters\n",
       "\n",
       "Given your height is 6 ft 4 inches, we will first convert feet to centimeters and then add the inches.\n",
       "\n",
       "6 feet = 6 * 30.48 = 182.88 centimeters\n",
       "4 inches = 4 * 2.54 = 10.16 centimeters\n",
       "\n",
       "Now, we add the centimeters from feet and inches to get your total height in centimeters.\n",
       "\n",
       "182.88 + 10.16 = 193.04 centimeters\n",
       "\n",
       "You are approximately 193.04 centimeters tall.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "====================================================================================================\n",
       "\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "====================================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "QUESTION: Who was the 12th person on the moon?\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "RESPONSE: Unfortunately, the answer is not a single person but rather a piece of trivia involving the Apollo 14 mission. Alan Shepard, Edgar Mitchell, and Stuart Roosa were the 11th, 12th, and 13th people to walk on the moon, respectively.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "====================================================================================================\n",
       "\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "====================================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "QUESTION: How many eyes does a blade of grass have?\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "RESPONSE: The correct answer is 1. Each blade of grass has a single tip that functions as an eye, known as an apical meristem. This eye is responsible for growth and photosynthesis. However, if we consider the entire root system, it can have multiple \"eyes\" or growth points.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "====================================================================================================\n",
       "\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for question, response in zip(qs, res):\n",
    "    print_text(\"=\"*100)\n",
    "    print_text(f\"QUESTION: {question['question']}\")\n",
    "    print_text(f\"RESPONSE: {response.content}\")\n",
    "    print_text(\"=\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5e4125",
   "metadata": {},
   "source": [
    "# Langchain Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a3955",
   "metadata": {},
   "source": [
    "## Simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8f683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: Which libraries and model providers offer LLMs?\n",
    "\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de737795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "The `transformers` library from Hugging Face, the `openai` library from OpenAI, and the `cohere` library from Cohere offer Large Language Models (LLMs).\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = chat_llm.invoke(prompt)\n",
    "time.sleep(3)\n",
    "print_text(text.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da8dce",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c54c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e4408cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Answer the question based on the context below. If the\n",
       "question cannot be answered using the information provided answer\n",
       "with \"I don't know\".\n",
       "\n",
       "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
       "Their superior performance over smaller models has made them incredibly\n",
       "useful for developers building NLP enabled applications. These models\n",
       "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
       "using the `openai` library, and via Cohere using the `cohere` library.\n",
       "\n",
       "Question: Which libraries and model providers offer LLMs?\n",
       "\n",
       "Answer: \n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_prompt = prompt_template.format(\n",
    "        query=\"Which libraries and model providers offer LLMs?\"\n",
    "    )\n",
    "print_text(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29aa7b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "The `transformers` library from Hugging Face, the `openai` library, and the `cohere` library offer Large Language Models (LLMs).\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_parser = StrOutputParser()\n",
    "chain = prompt_template | chat_llm | output_parser\n",
    "\n",
    "response = chain.invoke({\"query\": \"Which libraries and model providers offer LLMs?\"})\n",
    "time.sleep(3)\n",
    "print_text(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75565d",
   "metadata": {},
   "source": [
    "## Few-shot Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea079f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "FAQ\n",
       "================\n",
       "\n",
       "### Returning an Order\n",
       "\n",
       "#### Q: What is your return policy?\n",
       "\n",
       "A: We accept returns within 30 days with a valid receipt. Please contact us for further instructions on the return process.\n",
       "\n",
       "### Shipping and Delivery\n",
       "\n",
       "#### Q: Do you ship internationally?\n",
       "\n",
       "A: Yes, we ship to over 50 countries worldwide. Please note that international shipping rates and delivery times may vary.\n",
       "\n",
       "### Tracking Your Order\n",
       "\n",
       "#### Q: How can I track my order?\n",
       "\n",
       "A: To track your order, simply use the tracking link provided in your confirmation email. This will allow you to monitor the status of your shipment in real-time.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"Create an FAQ in Markdown based on the following questions and answers:\\n\"\n",
    "        \"Q1: What is your return policy?\\n\"\n",
    "        \"A1: We accept returns within 30 days with receipt.\\n\"\n",
    "        \"Q2: Do you ship internationally?\\n\"\n",
    "        \"A2: Yes, we ship to over 50 countries.\\n\"\n",
    "        \"Q3: How can I track my order?\\n\"\n",
    "        \"A3: Use the tracking link in your confirmation email.\"\n",
    "    ),\n",
    "    input_variables=[]  # No variables needed yet\n",
    ")\n",
    "\n",
    "chain = prompt | chat_llm | output_parser\n",
    "response = chain.invoke({})  # Empty dict since no input variables\n",
    "time.sleep(3)\n",
    "print_text(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0806243d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "# Frequently Asked Questions\n",
       "\n",
       "## [1. What payment methods do you accept?](#1-what-payment-methods-do-you-accept)\n",
       "\n",
       "We accept **Visa**, **Mastercard**, **PayPal**, and **Apple Pay**.\n",
       "\n",
       "## [2. Can I change my shipping address after ordering?](#2-can-i-change-my-shipping-address-after-ordering)\n",
       "\n",
       "Only if your order hasn't shipped yet. Contact support **ASAP**.\n",
       "\n",
       "## [3. Do you offer gift wrapping?](#3-do-you-offer-gift-wrapping)\n",
       "\n",
       "Yes! You can select gift wrapping during **checkout**.\n",
       "\n",
       "---\n",
       "\n",
       "You can easily navigate to each section using the anchor links provided. Just click on the section title to scroll to that part of the FAQ.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_str = \"\"\"\n",
    "Create a structured Markdown FAQ with anchor links, headers, and formatting conventions for readability.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Example input:\n",
    "Q1: What is your return policy?\n",
    "A1: We accept returns within 30 days with the original receipt.\n",
    "Q2: Do you ship internationally?\n",
    "A2: Yes, we ship to over 50 countries worldwide.\n",
    "Q3: How can I track my order?\n",
    "A3: After your order is shipped, you'll receive a tracking link via email.\n",
    "\n",
    "Example Output:\n",
    "\n",
    "# Frequently Asked Questions\n",
    "\n",
    "## [1. What is your return policy?](#1-what-is-your-return-policy)\n",
    "\n",
    "We accept returns within **30 days** with the original **receipt**.\n",
    "\n",
    "## [2. Do you ship internationally?](#2-do-you-ship-internationally)\n",
    "\n",
    "Yes, we ship to over **50 countries** worldwide.\n",
    "\n",
    "## [3. How can I track my order?](#3-how-can-i-track-my-order)\n",
    "\n",
    "After your order is shipped, you'll receive a **tracking link** via email.\n",
    "\n",
    "---\n",
    "\n",
    "Now generate the FAQ section for this data:\n",
    "Q1: What payment methods do you accept?\n",
    "A1: We accept Visa, Mastercard, PayPal, and Apple Pay.\n",
    "Q2: Can I change my shipping address after ordering?\n",
    "A2: Only if your order hasn't shipped yet. Contact support ASAP.\n",
    "Q3: Do you offer gift wrapping?\n",
    "A3: Yes! You can select gift wrapping during checkout.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Create a PromptTemplate with no input variables (static prompt)\n",
    "prompt = PromptTemplate(template=prompt_str, input_variables=[])\n",
    "\n",
    "chain = prompt | chat_llm | output_parser\n",
    "response = chain.invoke({})  # Empty dict since no input variables\n",
    "time.sleep(3)\n",
    "print_text(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63867dcf",
   "metadata": {},
   "source": [
    "## Few Shot Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fd59f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified examples with just 2 variables instead of 9\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": (\n",
    "            \"Q1: What is your return policy?\\n\"\n",
    "            \"A1: We accept returns within 30 days with the original receipt.\"\n",
    "        ),\n",
    "        \"output\": (\n",
    "            \"## [1. What is your return policy?](#1-what-is-your-return-policy)\\n\\n\"\n",
    "            \"We accept returns within **30 days** with the original **receipt**.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"input\": (\n",
    "            \"Q2: Do you ship internationally?\\n\"\n",
    "            \"A2: Yes, we ship to over 50 countries worldwide.\"\n",
    "        ),\n",
    "        \"output\": (\n",
    "            \"## [2. Do you ship internationally?](#2-do-you-ship-internationally)\\n\\n\"\n",
    "            \"Yes, we ship to over **50 countries** worldwide.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"input\": (\n",
    "            \"Q3: How can I track my order?\\n\"\n",
    "            \"A3: After your order is shipped, you'll receive a tracking link via email.\"\n",
    "        ),\n",
    "        \"output\": (\n",
    "            \"## [3. How can I track my order?](#3-how-can-i-track-my-order)\\n\\n\"\n",
    "            \"After your order is shipped, you'll receive a **tracking link** via email.\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "# Much simpler example template with only 2 variables\n",
    "example_template = \"\"\"Example input:\n",
    "{input}\n",
    "\n",
    "Example Output:\n",
    "# Frequently Asked Questions\\n\\n\n",
    "{output}\n",
    "\"\"\"\n",
    "\n",
    "# Create prompt template for examples\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# Instructions prefix\n",
    "prefix = \"\"\"Create a structured Markdown FAQ with anchor links, headers, and formatting conventions for readability.\n",
    "Make sure to bold key terms and important information in the answers.\n",
    "\n",
    "**Example:**\n",
    "\"\"\"\n",
    "\n",
    "# User input format and instructions\n",
    "suffix = \"\"\"\n",
    "Now generate the FAQ section for this data:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "# Create the few-shot prompt template\n",
    "faq_few_shot = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b686d2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Create a structured Markdown FAQ with anchor links, headers, and formatting conventions for readability.\n",
       "Make sure to bold key terms and important information in the answers.\n",
       "\n",
       "**Example:**\n",
       "\n",
       "Example input:\n",
       "Q1: What is your return policy?\n",
       "A1: We accept returns within 30 days with the original receipt.\n",
       "\n",
       "Example Output:\n",
       "# Frequently Asked Questions\n",
       "\n",
       "\n",
       "## [1. What is your return policy?](#1-what-is-your-return-policy)\n",
       "\n",
       "We accept returns within **30 days** with the original **receipt**.\n",
       "\n",
       "Example input:\n",
       "Q2: Do you ship internationally?\n",
       "A2: Yes, we ship to over 50 countries worldwide.\n",
       "\n",
       "Example Output:\n",
       "# Frequently Asked Questions\n",
       "\n",
       "\n",
       "## [2. Do you ship internationally?](#2-do-you-ship-internationally)\n",
       "\n",
       "Yes, we ship to over **50 countries** worldwide.\n",
       "\n",
       "Example input:\n",
       "Q3: How can I track my order?\n",
       "A3: After your order is shipped, you'll receive a tracking link via email.\n",
       "\n",
       "Example Output:\n",
       "# Frequently Asked Questions\n",
       "\n",
       "\n",
       "## [3. How can I track my order?](#3-how-can-i-track-my-order)\n",
       "\n",
       "After your order is shipped, you'll receive a **tracking link** via email.\n",
       "\n",
       "\n",
       "Now generate the FAQ section for this data:\n",
       "Q1: What payment methods do you accept?\n",
       "A1: We accept Visa, Mastercard, PayPal, and Apple Pay.\n",
       "Q2: Can I change my shipping address after ordering?\n",
       "A2: Only if your order hasn't shipped yet. Contact support ASAP.\n",
       "Q3: Do you offer gift wrapping?\n",
       "A3: Yes! You can select gift wrapping during checkout.\n",
       "\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See what the prompt looks like before sending to LLM\n",
    "user_input = \"\"\"Q1: What payment methods do you accept?\n",
    "A1: We accept Visa, Mastercard, PayPal, and Apple Pay.\n",
    "Q2: Can I change my shipping address after ordering?\n",
    "A2: Only if your order hasn't shipped yet. Contact support ASAP.\n",
    "Q3: Do you offer gift wrapping?\n",
    "A3: Yes! You can select gift wrapping during checkout.\"\"\"\n",
    "\n",
    "formatted_prompt = faq_few_shot.format(input=user_input)\n",
    "print_text(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6f46b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "# Frequently Asked Questions\n",
       "\n",
       "## [1. What payment methods do you accept?](#1-what-payment-methods-do-you-accept)\n",
       "\n",
       "We accept **Visa**, **Mastercard**, **PayPal**, and **Apple Pay**.\n",
       "\n",
       "## [2. Can I change my shipping address after ordering?](#2-can-i-change-my-shipping-address-after-ordering)\n",
       "\n",
       "**Only if your order hasn't shipped yet**. Contact our support team as soon as possible to make any necessary changes.\n",
       "\n",
       "## [3. Do you offer gift wrapping?](#3-do-you-offer-gift-wrapping)\n",
       "\n",
       "Yes! You can select gift wrapping during **checkout**.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain = faq_few_shot | chat_llm | output_parser\n",
    "\n",
    "# Execute with LCEL chain\n",
    "response = chain.invoke({\"input\": user_input})\n",
    "time.sleep(3)\n",
    "\n",
    "# Display the formatted FAQ (response is already a clean string)\n",
    "print_text(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a851f5d2",
   "metadata": {},
   "source": [
    "## Dynamic inclusion/exclusion of examples in FewShotPromptTemplate using LengthBasedExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f24dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note we're adding more FAQ examples to each individual example here\n",
    "# (how much you add isn't necessarily important - just that you're aligning\n",
    "# examples as closely as possible to your use-case)\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"\"\"Q1: What is your return policy?\n",
    "A1: We accept returns within 30 days with the original receipt.\n",
    "Q2: Do you ship internationally?\n",
    "A2: Yes, we ship to over 50 countries worldwide.\n",
    "Q3: How can I track my order?\n",
    "A3: After your order is shipped, you'll receive a tracking link via email.\"\"\",\n",
    "        \n",
    "        \"output\": \"\"\"## [1. What is your return policy?](#1-what-is-your-return-policy)\n",
    "\n",
    "We accept returns within **30 days** with the original **receipt**.\n",
    "\n",
    "## [2. Do you ship internationally?](#2-do-you-ship-internationally)\n",
    "\n",
    "Yes, we ship to over **50 countries** worldwide.\n",
    "\n",
    "## [3. How can I track my order?](#3-how-can-i-track-my-order)\n",
    "\n",
    "After your order is shipped, you'll receive a **tracking link** via email.\n",
    "\n",
    "---\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Q1: What payment methods do you accept?\n",
    "A1: We accept Visa, Mastercard, PayPal, and Apple Pay.\n",
    "Q2: Can I change my shipping address after ordering?\n",
    "A2: Only if your order hasn't shipped yet. Contact support ASAP.\n",
    "Q3: Do you offer gift wrapping?\n",
    "A3: Yes! You can select gift wrapping during checkout.\"\"\",\n",
    "        \n",
    "        \"output\": \"\"\"## [1. What payment methods do you accept?](#1-what-payment-methods-do-you-accept)\n",
    "\n",
    "We accept **Visa**, **Mastercard**, **PayPal**, and **Apple Pay**.\n",
    "\n",
    "## [2. Can I change my shipping address after ordering?](#2-can-i-change-my-shipping-address-after-ordering)\n",
    "\n",
    "Only if your order hasn't shipped yet. Contact support **ASAP**.\n",
    "\n",
    "## [3. Do you offer gift wrapping?](#3-do-you-offer-gift-wrapping)\n",
    "\n",
    "Yes! You can select **gift wrapping** during checkout.\n",
    "\n",
    "---\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Q1: What are your store hours?\n",
    "A1: We're open Monday through Friday from 9am to 9pm, and weekends from 10am to 7pm.\n",
    "Q2: Do you offer price matching?\n",
    "A2: Yes, we'll match any price from authorized retailers for identical products.\n",
    "Q3: What is your warranty policy?\n",
    "A3: All electronics come with a standard 1-year manufacturer warranty.\"\"\",\n",
    "        \n",
    "        \"output\": \"\"\"## [1. What are your store hours?](#1-what-are-your-store-hours)\n",
    "\n",
    "We're open **Monday through Friday** from **9am to 9pm**, and **weekends** from **10am to 7pm**.\n",
    "\n",
    "## [2. Do you offer price matching?](#2-do-you-offer-price-matching)\n",
    "\n",
    "Yes, we'll match any price from **authorized retailers** for **identical products**.\n",
    "\n",
    "## [3. What is your warranty policy?](#3-what-is-your-warranty-policy)\n",
    "\n",
    "All electronics come with a standard **1-year manufacturer warranty**.\n",
    "\n",
    "---\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Q1: How do I contact customer service?\n",
    "A1: You can reach us at support@example.com or call 555-123-4567.\n",
    "Q2: Do you offer same-day delivery?\n",
    "A2: Yes, for orders placed before 2pm in selected metro areas.\n",
    "Q3: How do I cancel an order?\n",
    "A3: Log into your account and cancel within 1 hour of placing the order.\"\"\",\n",
    "        \n",
    "        \"output\": \"\"\"## [1. How do I contact customer service?](#1-how-do-i-contact-customer-service)\n",
    "\n",
    "You can reach us at **support@example.com** or call **555-123-4567**.\n",
    "\n",
    "## [2. Do you offer same-day delivery?](#2-do-you-offer-same-day-delivery)\n",
    "\n",
    "Yes, for orders placed before **2pm** in selected **metro areas**.\n",
    "\n",
    "## [3. How do I cancel an order?](#3-how-do-i-cancel-an-order)\n",
    "\n",
    "Log into your account and cancel within **1 hour** of placing the order.\n",
    "\n",
    "---\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Q1: Do you offer student discounts?\n",
    "A1: Yes, students with valid ID receive 15% off all purchases.\n",
    "Q2: What is your privacy policy?\n",
    "A2: We never share your personal information with third parties without consent.\n",
    "Q3: Are your products environmentally friendly?\n",
    "A3: We use recyclable packaging and offer carbon-neutral shipping options.\"\"\",\n",
    "        \n",
    "        \"output\": \"\"\"## [1. Do you offer student discounts?](#1-do-you-offer-student-discounts)\n",
    "\n",
    "Yes, students with valid ID receive **15% off** all purchases.\n",
    "\n",
    "## [2. What is your privacy policy?](#2-what-is-your-privacy-policy)\n",
    "\n",
    "We **never share** your personal information with third parties without consent.\n",
    "\n",
    "## [3. Are your products environmentally friendly?](#3-are-your-products-environmentally-friendly)\n",
    "\n",
    "We use **recyclable packaging** and offer **carbon-neutral shipping** options.\n",
    "\n",
    "---\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Q1: How do I apply for a refund?\n",
    "A1: Submit your request through our customer portal with your order number and reason.\n",
    "Q2: Do you have a loyalty program?\n",
    "A2: Yes! Earn 1 point for every dollar spent and redeem for discounts.\n",
    "Q3: What are the system requirements?\n",
    "A3: Our software requires Windows 10/11 or macOS 10.15+, 8GB RAM, and 2GB storage.\"\"\",\n",
    "        \n",
    "        \"output\": \"\"\"## [1. How do I apply for a refund?](#1-how-do-i-apply-for-a-refund)\n",
    "\n",
    "Submit your request through our **customer portal** with your **order number** and reason.\n",
    "\n",
    "## [2. Do you have a loyalty program?](#2-do-you-have-a-loyalty-program)\n",
    "\n",
    "Yes! Earn **1 point** for every dollar spent and redeem for **discounts**.\n",
    "\n",
    "## [3. What are the system requirements?](#3-what-are-the-system-requirements)\n",
    "\n",
    "Our software requires **Windows 10/11** or **macOS 10.15+**, **8GB RAM**, and **2GB storage**.\n",
    "\n",
    "---\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Q1: How long does shipping take?\n",
    "A1: Standard shipping takes 3-5 business days, and express shipping takes 1-2 business days.\n",
    "Q2: Do you have physical stores?\n",
    "A2: Yes, we have 12 locations across North America. Find the nearest one on our website.\n",
    "Q3: How do I reset my password?\n",
    "A3: Click 'Forgot Password' on the login page and follow the email instructions.\"\"\",\n",
    "\n",
    "        \"output\": \"\"\"## [1. How long does shipping take?](#1-how-long-does-shipping-take)\n",
    "\n",
    "Standard shipping takes **3-5 business days**, and express shipping takes **1-2 business days**.\n",
    "\n",
    "## [2. Do you have physical stores?](#2-do-you-have-physical-stores)\n",
    "\n",
    "Yes, we have **12 locations** across North America. Find the nearest one on our **website**.\n",
    "\n",
    "## [3. How do I reset my password?](#3-how-do-i-reset-my-password)\n",
    "\n",
    "Click **'Forgot Password'** on the login page and follow the email instructions.\n",
    "\n",
    "---\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Q1: What's your wholesale policy?\n",
    "A1: For orders over $500, contact our wholesale department for special pricing.\n",
    "Q2: How can I become a vendor?\n",
    "A2: Fill out the vendor application form on our Partners page for consideration.\n",
    "Q3: Do you offer installation services?\n",
    "A3: Yes, professional installation is available for an additional fee in most areas.\"\"\",\n",
    "        \n",
    "        \"output\": \"\"\"## [1. What's your wholesale policy?](#1-whats-your-wholesale-policy)\n",
    "\n",
    "For orders over **$500**, contact our **wholesale department** for special pricing.\n",
    "\n",
    "## [2. How can I become a vendor?](#2-how-can-i-become-a-vendor)\n",
    "\n",
    "Fill out the **vendor application form** on our **Partners page** for consideration.\n",
    "\n",
    "## [3. Do you offer installation services?](#3-do-you-offer-installation-services)\n",
    "\n",
    "Yes, **professional installation** is available for an additional fee in **most areas**.\n",
    "\n",
    "---\"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2b91c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=700  # this sets the max length that examples should be\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37d74b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'are', 'a', 'total', 'of', '8', 'words', 'here.', 'Plus', '6', 'here,', 'totaling', '14', 'words.'] 14\n"
     ]
    }
   ],
   "source": [
    "some_text = \"There are a total of 8 words here.\\nPlus 6 here, totaling 14 words.\"\n",
    "\n",
    "words = re.split('[\\n ]', some_text)\n",
    "print(words, len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0aa173b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then create the dynamic prompt template\n",
    "dynamic_faq_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # use example_selector instead of examples\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\"],  # simplified to just one variable\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "166b30bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Create a structured Markdown FAQ with anchor links, headers, and formatting conventions for readability.\n",
       "Make sure to bold key terms and important information in the answers.\n",
       "\n",
       "**Example:**\n",
       "\n",
       "Example input:\n",
       "Q1: What is your return policy?\n",
       "A1: We accept returns within 30 days with the original receipt.\n",
       "Q2: Do you ship internationally?\n",
       "A2: Yes, we ship to over 50 countries worldwide.\n",
       "Q3: How can I track my order?\n",
       "A3: After your order is shipped, you'll receive a tracking link via email.\n",
       "\n",
       "Example Output:\n",
       "# Frequently Asked Questions\n",
       "\n",
       "\n",
       "## [1. What is your return policy?](#1-what-is-your-return-policy)\n",
       "\n",
       "We accept returns within **30 days** with the original **receipt**.\n",
       "\n",
       "## [2. Do you ship internationally?](#2-do-you-ship-internationally)\n",
       "\n",
       "Yes, we ship to over **50 countries** worldwide.\n",
       "\n",
       "## [3. How can I track my order?](#3-how-can-i-track-my-order)\n",
       "\n",
       "After your order is shipped, you'll receive a **tracking link** via email.\n",
       "\n",
       "---\n",
       "\n",
       "Example input:\n",
       "Q1: What payment methods do you accept?\n",
       "A1: We accept Visa, Mastercard, PayPal, and Apple Pay.\n",
       "Q2: Can I change my shipping address after ordering?\n",
       "A2: Only if your order hasn't shipped yet. Contact support ASAP.\n",
       "Q3: Do you offer gift wrapping?\n",
       "A3: Yes! You can select gift wrapping during checkout.\n",
       "\n",
       "Example Output:\n",
       "# Frequently Asked Questions\n",
       "\n",
       "\n",
       "## [1. What payment methods do you accept?](#1-what-payment-methods-do-you-accept)\n",
       "\n",
       "We accept **Visa**, **Mastercard**, **PayPal**, and **Apple Pay**.\n",
       "\n",
       "## [2. Can I change my shipping address after ordering?](#2-can-i-change-my-shipping-address-after-ordering)\n",
       "\n",
       "Only if your order hasn't shipped yet. Contact support **ASAP**.\n",
       "\n",
       "## [3. Do you offer gift wrapping?](#3-do-you-offer-gift-wrapping)\n",
       "\n",
       "Yes! You can select **gift wrapping** during checkout.\n",
       "\n",
       "---\n",
       "\n",
       "Example input:\n",
       "Q1: What are your store hours?\n",
       "A1: We're open Monday through Friday from 9am to 9pm, and weekends from 10am to 7pm.\n",
       "Q2: Do you offer price matching?\n",
       "A2: Yes, we'll match any price from authorized retailers for identical products.\n",
       "Q3: What is your warranty policy?\n",
       "A3: All electronics come with a standard 1-year manufacturer warranty.\n",
       "\n",
       "Example Output:\n",
       "# Frequently Asked Questions\n",
       "\n",
       "\n",
       "## [1. What are your store hours?](#1-what-are-your-store-hours)\n",
       "\n",
       "We're open **Monday through Friday** from **9am to 9pm**, and **weekends** from **10am to 7pm**.\n",
       "\n",
       "## [2. Do you offer price matching?](#2-do-you-offer-price-matching)\n",
       "\n",
       "Yes, we'll match any price from **authorized retailers** for **identical products**.\n",
       "\n",
       "## [3. What is your warranty policy?](#3-what-is-your-warranty-policy)\n",
       "\n",
       "All electronics come with a standard **1-year manufacturer warranty**.\n",
       "\n",
       "---\n",
       "\n",
       "Example input:\n",
       "Q1: How do I contact customer service?\n",
       "A1: You can reach us at support@example.com or call 555-123-4567.\n",
       "Q2: Do you offer same-day delivery?\n",
       "A2: Yes, for orders placed before 2pm in selected metro areas.\n",
       "Q3: How do I cancel an order?\n",
       "A3: Log into your account and cancel within 1 hour of placing the order.\n",
       "\n",
       "Example Output:\n",
       "# Frequently Asked Questions\n",
       "\n",
       "\n",
       "## [1. How do I contact customer service?](#1-how-do-i-contact-customer-service)\n",
       "\n",
       "You can reach us at **support@example.com** or call **555-123-4567**.\n",
       "\n",
       "## [2. Do you offer same-day delivery?](#2-do-you-offer-same-day-delivery)\n",
       "\n",
       "Yes, for orders placed before **2pm** in selected **metro areas**.\n",
       "\n",
       "## [3. How do I cancel an order?](#3-how-do-i-cancel-an-order)\n",
       "\n",
       "Log into your account and cancel within **1 hour** of placing the order.\n",
       "\n",
       "---\n",
       "\n",
       "Example input:\n",
       "Q1: Do you offer student discounts?\n",
       "A1: Yes, students with valid ID receive 15% off all purchases.\n",
       "Q2: What is your privacy policy?\n",
       "A2: We never share your personal information with third parties without consent.\n",
       "Q3: Are your products environmentally friendly?\n",
       "A3: We use recyclable packaging and offer carbon-neutral shipping options.\n",
       "\n",
       "Example Output:\n",
       "# Frequently Asked Questions\n",
       "\n",
       "\n",
       "## [1. Do you offer student discounts?](#1-do-you-offer-student-discounts)\n",
       "\n",
       "Yes, students with valid ID receive **15% off** all purchases.\n",
       "\n",
       "## [2. What is your privacy policy?](#2-what-is-your-privacy-policy)\n",
       "\n",
       "We **never share** your personal information with third parties without consent.\n",
       "\n",
       "## [3. Are your products environmentally friendly?](#3-are-your-products-environmentally-friendly)\n",
       "\n",
       "We use **recyclable packaging** and offer **carbon-neutral shipping** options.\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "Now generate the FAQ section for this data:\n",
       "Q1: What payment methods do you accept?\n",
       "A1: We accept Visa, Mastercard, PayPal, and Apple Pay.\n",
       "Q2: Can I change my shipping address after ordering?\n",
       "A2: Only if your order hasn't shipped yet. Contact support ASAP.\n",
       "Q3: Do you offer gift wrapping?\n",
       "A3: Yes! You can select gift wrapping during checkout.\n",
       "\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using simplified input format\n",
    "user_input = \"\"\"Q1: What payment methods do you accept?\n",
    "A1: We accept Visa, Mastercard, PayPal, and Apple Pay.\n",
    "Q2: Can I change my shipping address after ordering?\n",
    "A2: Only if your order hasn't shipped yet. Contact support ASAP.\n",
    "Q3: Do you offer gift wrapping?\n",
    "A3: Yes! You can select gift wrapping during checkout.\"\"\"\n",
    "\n",
    "formatted_prompt = dynamic_faq_prompt.format(input=user_input)\n",
    "print_text(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85283c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "# Frequently Asked Questions\n",
       "\n",
       "\n",
       "## [1. What payment methods do you accept?](#1-what-payment-methods-do-you-accept)\n",
       "\n",
       "We accept **Visa**, **Mastercard**, **PayPal**, and **Apple Pay**.\n",
       "\n",
       "## [2. Can I change my shipping address after ordering?](#2-can-i-change-my-shipping-address-after-ordering)\n",
       "\n",
       "Only if your order hasn't shipped yet. **Contact support ASAP**.\n",
       "\n",
       "## [3. Do you offer gift wrapping?](#3-do-you-offer-gift-wrapping)\n",
       "\n",
       "Yes! You can select **gift wrapping** during checkout.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dynamic_chain = dynamic_faq_prompt | chat_llm | output_parser\n",
    "\n",
    "# Execute with LCEL chain\n",
    "response = dynamic_chain.invoke({\"input\": user_input})\n",
    "time.sleep(3)\n",
    "print_text(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc22874",
   "metadata": {},
   "source": [
    "## LengthBasedExampleSelector working when user input is much longer and using more of the context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fac16b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using simplified input format with very long questions and answers\n",
    "user_input = \"\"\"Q1: What are all the different payment methods that you accept for online purchases, including credit cards, digital wallets, bank transfers, and any special financing options that might be available for customers?\n",
    "A1: We accept a comprehensive range of payment methods to accommodate all our customers' preferences and needs. For credit cards, we accept Visa, Mastercard, American Express, and Discover. We also support digital wallet payments through PayPal, Apple Pay, Google Pay, Samsung Pay, and Amazon Pay. Additionally, we offer bank transfer options including ACH transfers, wire transfers, and direct debit for customers who prefer traditional banking methods. For larger purchases, we provide financing options through Affirm, Klarna, and our own in-house financing program with flexible payment plans ranging from 6 to 36 months. We also accept cryptocurrency payments including Bitcoin, Ethereum, and several other major cryptocurrencies for tech-savvy customers.\n",
    "Q2: Is it possible for me to modify or completely change my shipping address after I have already placed and confirmed my order, and if so, what are the specific conditions, timeframes, and procedures that I need to follow?\n",
    "A2: Yes, it is possible to modify your shipping address, but this depends entirely on the current status of your order in our fulfillment process. If your order has not yet been processed by our warehouse team and is still in 'pending' or 'confirmed' status, you can easily change the shipping address by logging into your account and accessing the order management section. However, once your order enters the 'processing' phase and our warehouse team begins preparing your items for shipment, address changes become much more complicated and may not be possible. If your order has already shipped, unfortunately we cannot redirect the package to a different address, but you can contact the shipping carrier directly to arrange for package interception or redirection services, though additional fees may apply. For the best chance of successful address modification, we strongly recommend contacting our customer support team immediately at support@company.com or calling our toll-free number.\n",
    "Q3: Do you provide gift wrapping services for the items that I purchase, and if you do, what are the different options available, what are the costs involved, and can I include personalized messages or special requests?\n",
    "A3: Absolutely! We offer comprehensive gift wrapping services to make your purchases extra special for any occasion. We have several gift wrapping options available: our standard gift wrap features elegant wrapping paper in various colors and patterns with matching ribbon and a bow for an additional $4.99 per item. Our premium gift wrap option includes luxury wrapping paper, silk ribbon, and decorative embellishments for $9.99 per item. For special occasions, we offer themed wrapping for holidays, birthdays, weddings, and baby showers at $7.99 per item. You can also add personalized gift messages up to 250 characters at no additional cost, and we'll include them on beautiful greeting cards. For an extra $2.99, you can upload custom messages or even photos to be printed on special cards. All gift-wrapped items are carefully packaged to ensure they arrive in perfect condition, and we offer discrete packaging options if you're sending gifts directly to recipients.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c7215a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a structured Markdown FAQ with anchor links, headers, and formatting conventions for readability.\n",
      "Make sure to bold key terms and important information in the answers.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Example input:\n",
      "Q1: What is your return policy?\n",
      "A1: We accept returns within 30 days with the original receipt.\n",
      "Q2: Do you ship internationally?\n",
      "A2: Yes, we ship to over 50 countries worldwide.\n",
      "Q3: How can I track my order?\n",
      "A3: After your order is shipped, you'll receive a tracking link via email.\n",
      "\n",
      "Example Output:\n",
      "# Frequently Asked Questions\n",
      "\n",
      "\n",
      "## [1. What is your return policy?](#1-what-is-your-return-policy)\n",
      "\n",
      "We accept returns within **30 days** with the original **receipt**.\n",
      "\n",
      "## [2. Do you ship internationally?](#2-do-you-ship-internationally)\n",
      "\n",
      "Yes, we ship to over **50 countries** worldwide.\n",
      "\n",
      "## [3. How can I track my order?](#3-how-can-i-track-my-order)\n",
      "\n",
      "After your order is shipped, you'll receive a **tracking link** via email.\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Now generate the FAQ section for this data:\n",
      "Q1: What are all the different payment methods that you accept for online purchases, including credit cards, digital wallets, bank transfers, and any special financing options that might be available for customers?\n",
      "A1: We accept a comprehensive range of payment methods to accommodate all our customers' preferences and needs. For credit cards, we accept Visa, Mastercard, American Express, and Discover. We also support digital wallet payments through PayPal, Apple Pay, Google Pay, Samsung Pay, and Amazon Pay. Additionally, we offer bank transfer options including ACH transfers, wire transfers, and direct debit for customers who prefer traditional banking methods. For larger purchases, we provide financing options through Affirm, Klarna, and our own in-house financing program with flexible payment plans ranging from 6 to 36 months. We also accept cryptocurrency payments including Bitcoin, Ethereum, and several other major cryptocurrencies for tech-savvy customers.\n",
      "Q2: Is it possible for me to modify or completely change my shipping address after I have already placed and confirmed my order, and if so, what are the specific conditions, timeframes, and procedures that I need to follow?\n",
      "A2: Yes, it is possible to modify your shipping address, but this depends entirely on the current status of your order in our fulfillment process. If your order has not yet been processed by our warehouse team and is still in 'pending' or 'confirmed' status, you can easily change the shipping address by logging into your account and accessing the order management section. However, once your order enters the 'processing' phase and our warehouse team begins preparing your items for shipment, address changes become much more complicated and may not be possible. If your order has already shipped, unfortunately we cannot redirect the package to a different address, but you can contact the shipping carrier directly to arrange for package interception or redirection services, though additional fees may apply. For the best chance of successful address modification, we strongly recommend contacting our customer support team immediately at support@company.com or calling our toll-free number.\n",
      "Q3: Do you provide gift wrapping services for the items that I purchase, and if you do, what are the different options available, what are the costs involved, and can I include personalized messages or special requests?\n",
      "A3: Absolutely! We offer comprehensive gift wrapping services to make your purchases extra special for any occasion. We have several gift wrapping options available: our standard gift wrap features elegant wrapping paper in various colors and patterns with matching ribbon and a bow for an additional $4.99 per item. Our premium gift wrap option includes luxury wrapping paper, silk ribbon, and decorative embellishments for $9.99 per item. For special occasions, we offer themed wrapping for holidays, birthdays, weddings, and baby showers at $7.99 per item. You can also add personalized gift messages up to 250 characters at no additional cost, and we'll include them on beautiful greeting cards. For an extra $2.99, you can upload custom messages or even photos to be printed on special cards. All gift-wrapped items are carefully packaged to ensure they arrive in perfect condition, and we offer discrete packaging options if you're sending gifts directly to recipients.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formatted_prompt = dynamic_faq_prompt.format(input=user_input)\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f91976d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "# Frequently Asked Questions\n",
       "\n",
       "## [1. What payment methods do you accept for online purchases?](#1-what-payment-methods-do-you-accept-for-online-purchases)\n",
       "\n",
       "We accept a comprehensive range of payment methods to accommodate all our customers' preferences and needs. For **credit cards**, we accept **Visa**, **Mastercard**, **American Express**, and **Discover**. We also support digital wallet payments through **PayPal**, **Apple Pay**, **Google Pay**, **Samsung Pay**, and **Amazon Pay**. Additionally, we offer **bank transfer** options including **ACH transfers**, **wire transfers**, and **direct debit** for customers who prefer traditional banking methods. For larger purchases, we provide financing options through **Affirm**, **Klarna**, and our own in-house financing program with flexible payment plans ranging from **6 to 36 months**. We also accept **cryptocurrency payments** including **Bitcoin**, **Ethereum**, and several other major cryptocurrencies for tech-savvy customers.\n",
       "\n",
       "## [2. Can I modify or change my shipping address after I have placed and confirmed my order?](#2-can-i-modify-or-change-my-shipping-address-after-i-have-placed-and-confirmed-my-order)\n",
       "\n",
       "Yes, it is possible to modify your shipping address, but this depends entirely on the current status of your order in our fulfillment process. If your order has not yet been processed by our warehouse team and is still in '**pending**' or '**\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute with LCEL chain\n",
    "response = dynamic_chain.invoke(user_input)\n",
    "time.sleep(3)\n",
    "\n",
    "# Display the formatted FAQ (response is already a clean string)\n",
    "print_text(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e5f44",
   "metadata": {},
   "source": [
    "# Langchain New Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ad7389",
   "metadata": {},
   "source": [
    "## New Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad78bdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "I'm doing well, thank you for asking. I'm a large language model, so I don't have feelings like humans do, but I'm always ready to help answer any questions or provide information on a wide range of topics. How can I assist you today?\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the message templates\n",
    "system_template = \"You are a helpful assistant.\"\n",
    "human_template = \"{input}\"\n",
    "\n",
    "# Create the prompt template\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template)\n",
    "])\n",
    "\n",
    "# Create the chain\n",
    "chain = prompt | chat_llm | StrOutputParser()\n",
    "\n",
    "# Test the chain\n",
    "result = chain.invoke({\"input\": \"Hi AI, how are you today?\"})\n",
    "time.sleep(3)\n",
    "print_text(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "626e9839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "String theory is a fundamental concept in modern physics that attempts to unify the principles of quantum mechanics and general relativity. It's a complex and mind-bending topic, but I'll try to break it down for you in simple terms.\n",
       "\n",
       "**What is String Theory?**\n",
       "\n",
       "String theory proposes that the fundamental building blocks of the universe are not particles, but tiny, vibrating strings. These strings are thought to be the basic units of matter and energy, and they can vibrate at different frequencies to create various particles, like electrons and photons.\n",
       "\n",
       "**Key Concepts:**\n",
       "\n",
       "1. **Strings:** The fundamental objects in string theory are one-dimensional strings, which are too small to be observed directly. They're like tiny, vibrating filaments that exist at the quantum level.\n",
       "2. **Vibrational Modes:** The strings vibrate at different frequencies, analogous to the strings on a violin. Each frequency corresponds to a specific particle, like an electron or a photon.\n",
       "3. **Extra Dimensions:** String theory requires the existence of more than the three spatial dimensions (length, width, and height) and one time dimension we experience in everyday life. These additional dimensions are \"curled up\" or \"compactified\" so tightly that they're not directly observable.\n",
       "4. **Superstrings:** There are two main types of strings: open strings (with free ends) and closed strings (forming a loop). Open strings can vibrate in different modes to create particles, while closed strings can be thought of as a\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create initial messages\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"Hi AI, how are you today?\"),\n",
    "    (\"ai\", \"I'm great thank you. How can I help you?\"),\n",
    "    (\"human\", \"I'd like to understand string theory.\")\n",
    "])\n",
    "\n",
    "# Create the chain using LCEL pipe syntax\n",
    "chain = prompt | chat_llm | StrOutputParser()\n",
    "\n",
    "# Get response using LCEL\n",
    "res = chain.invoke({})\n",
    "time.sleep(3)\n",
    "print_text(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eff84dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Physicists believe that string theory can produce a unified theory for several reasons:\n",
       "\n",
       "1. **Unifying Quantum Mechanics and General Relativity:** String theory attempts to merge two major areas of physics: quantum mechanics (describing the behavior of particles at the atomic and subatomic level) and general relativity (describing gravity and the large-scale structure of the universe). General relativity is a theory of gravity, while quantum mechanics is a theory of particles. String theory tries to reconcile these two theories by showing how gravity and particles are manifestations of the same underlying phenomenon.\n",
       "\n",
       "2. **Including All Fundamental Forces:** String theory attempts to unify the four fundamental forces of nature:\n",
       "\t* Gravity (described by general relativity)\n",
       "\t* Electromagnetism\n",
       "\t* The strong nuclear force (which holds quarks together inside protons and neutrons)\n",
       "\t* The weak nuclear force (responsible for certain types of radioactive decay)\n",
       "\n",
       "3. **Predicting New Particles:** String theory predicts the existence of new particles that are not yet observed in experiments. These particles could be discovered in future experiments, which would provide evidence for string theory.\n",
       "\n",
       "4. **Solving the Black Hole Information Paradox:** String theory provides an explanation for the black hole information paradox, which questions what happens to the information contained in matter that falls into a black hole. String theory suggests that this information is preserved, but in a form that's not yet understood.\n",
       "\n",
       "5. **Mathematical Consistency:** String theory has\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the follow-up question, we can extend the existing prompt\n",
    "prompt.extend([\n",
    "    (\"ai\", res),  # Previous AI response\n",
    "    (\"human\", \"Why do physicists believe it can produce a 'unified theory'?\")\n",
    "])\n",
    "\n",
    "# Create the chain using LCEL pipe syntax\n",
    "chain = prompt | chat_llm | StrOutputParser()\n",
    "\n",
    "# Get response\n",
    "result = chain.invoke({})\n",
    "time.sleep(3)\n",
    "print_text(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ed28898",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\n",
    "    \"English\",\n",
    "    \"Esperanto\",\n",
    "    \"Spanish\",\n",
    "    # \"French\",\n",
    "    # \"German\",\n",
    "    # \"Italian\",\n",
    "    # \"Portuguese\",\n",
    "    # \"Dutch\",\n",
    "    # \"Russian\",\n",
    "    # \"Chinese (Simplified)\",\n",
    "    # \"Chinese (Traditional)\",\n",
    "    # \"Japanese\",\n",
    "    # \"Korean\",\n",
    "    # \"Arabic\",\n",
    "    # \"Hindi\",\n",
    "    # \"Turkish\",\n",
    "    # \"Swedish\",\n",
    "    # \"Danish\",\n",
    "    # \"Norwegian\",\n",
    "    # \"Finnish\",\n",
    "    # \"Polish\",\n",
    "    # \"Czech\",\n",
    "    # \"Hungarian\",\n",
    "    # \"Greek\",\n",
    "    # \"Hebrew\",\n",
    "    # \"Vietnamese\",\n",
    "    # \"Thai\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "272f6e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Translate this input <INPUT_START> I hope when you come the weather will be clement. <INPUT_END>  into Spanish. Do not include any other text in your response.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts.chat import HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "# Create the prompt template\n",
    "human_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"Translate this input <INPUT_START> {input} <INPUT_END>  into {language}. Do not include any other text in your response.\"\n",
    ")\n",
    "chat_prompt = ChatPromptTemplate([human_template])\n",
    "\n",
    "# Format with dynamic input\n",
    "chat_prompt_value = chat_prompt.format_prompt(\n",
    "    input=\"I hope when you come the weather will be clement.\", # Extra points if you get the reference.\n",
    "    language=\"Spanish\"\n",
    ")\n",
    "\n",
    "chat_prompt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44d5b36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Translate this input <INPUT_START> I hope when you come the weather will be clement. <INPUT_END>  into Spanish. Do not include any other text in your response.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_value.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d1fb491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Translate this input <INPUT_START> I hope when you come the weather will be clement. <INPUT_END>  into Spanish. Do not include any other text in your response.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_value.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a2f9a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "=== Response in English ===\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "I hope when you come the weather will be nice.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "==================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "=== Response in Esperanto ===\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Mi esperas, ke kiam vi venos, la vetero estos milda.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "==================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "=== Response in Spanish ===\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Espero que cuando vengas el tiempo ser agradable.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "==================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "human_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"Translate this input '{input}' into {language}. Do not include any other text in your response.\"\n",
    ")\n",
    "system_template = SystemMessagePromptTemplate.from_template(\"You are a helpful assistant.\")\n",
    "\n",
    "# Create the chain using LCEL pipe syntax\n",
    "chain = (\n",
    "    ChatPromptTemplate([system_template, human_template])\n",
    "    | chat_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Loop through each language\n",
    "for language in languages:\n",
    "    print_text(f\"\\n=== Response in {language} ===\")\n",
    "\n",
    "    # Invoke the chain with our inputs\n",
    "    result = chain.invoke({\n",
    "        \"input\": \"I hope when you come the weather will be clement.\",\n",
    "        \"language\": language\n",
    "    })\n",
    "    time.sleep(3)\n",
    "\n",
    "    print_text(result)\n",
    "    print_text(\"=\" * 50)  # Separator for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e85fb840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "=== Technical Translation in English ===\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "    Status: 500 Internal Server Error\n",
       "    Response: {\n",
       "        'error': 'Database connection failed',\n",
       "        'code': 'DB_001',\n",
       "        'timestamp': '2024-03-20T10:30:00Z'\n",
       "    }\n",
       "\n",
       "    Technical Note: This error occurs when the application fails to connect to the database.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "=== Technical Translation in Esperanto ===\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Status: 500 Interna Servoba Krizo\n",
       "    Respondo: {\n",
       "        'eraro': 'Databazo konektio malsukcesis',\n",
       "        'kodo': 'DB_001',\n",
       "        'tempo': '2024-03-20T10:30:00Z'\n",
       "    }\n",
       "\n",
       "    Teknika Noto: i tiu eraro okazas, kiam la aplikao ne povas konekti al la databazo.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "=== Technical Translation in Spanish ===\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Estatus: 500 Error interno del servidor del servidor\n",
       "Respuesta: {\n",
       "    'error': 'Fall la conexin a la base de datos',\n",
       "    'code': 'DB_001',\n",
       "    'timestamp': '2024-03-20T10:30:00Z'\n",
       "}\n",
       "\n",
       "Nota tcnica: Este error ocurre cuando la aplicacin no puede conectarse a la base de datos.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create few-shot examples for technical content formatting\n",
    "system_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are a technical translator. You must maintain the exact same format and structure in your translations.\n",
    "    Only translate the explanatory text, keeping all technical terms, numbers, and formatting unchanged.\n",
    "\n",
    "    Example input and output pairs:\n",
    "\n",
    "    Input: \"Error 404: Page not found\"\n",
    "    Output: \"Error 404: Pgina no encontrada\"\n",
    "\n",
    "    Input: \"Status: 200 OK\n",
    "    Response: {{\n",
    "        'data': 'success',\n",
    "        'message': 'Operation completed'\n",
    "    }}\"\n",
    "    Output: \"Status: 200 OK\n",
    "    Response: {{\n",
    "        'data': 'success',\n",
    "        'message': 'Operacin completada'\n",
    "    }}\"\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Example of a technical input\n",
    "human_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"Translate this technical information to {language}:\n",
    "\n",
    "    Status: 500 Internal Server Error\n",
    "    Response: {{\n",
    "        'error': 'Database connection failed',\n",
    "        'code': 'DB_001',\n",
    "        'timestamp': '2024-03-20T10:30:00Z'\n",
    "    }}\n",
    "\n",
    "    Technical Note: This error occurs when the application cannot connect to the database.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Create the chain using LCEL pipe syntax\n",
    "chain = (\n",
    "    ChatPromptTemplate([system_template, human_template])\n",
    "    | chat_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Loop through each language\n",
    "for language in languages:\n",
    "    print_text(f\"\\n=== Technical Translation in {language} ===\")\n",
    "\n",
    "    # Invoke the chain with our input\n",
    "    result = chain.invoke({\"language\": language})\n",
    "    time.sleep(3)\n",
    "\n",
    "    print_text(result)\n",
    "    print_text(\"=\" * 80)  # Separator for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c071aec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "=== Technical Translation in English ===\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "    Status: 500 Internal Server Error\n",
       "    Response: {\n",
       "        'error': 'Database connection failed',\n",
       "        'code': 'DB_001',\n",
       "        'timestamp': '2024-03-20T10:30:00Z'\n",
       "    }\n",
       "\n",
       "    Technical Note: This error occurs when the application fails to establish a connection to the database.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "=== Technical Translation in Esperanto ===\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Statuso: 500 Interna Servo-ero de la Servilo\n",
       "Ripozo: {\n",
       "    'eraro': 'Falsita konekto al la datumbazo',\n",
       "    'kodo': 'DB_001',\n",
       "    'tempo': '2024-03-20T10:30:00Z'\n",
       "}\n",
       "\n",
       "Teknika Notacio: i tiu eraro okazas kiam la aplikilo ne sukcesas konektii al la datumbazo.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "=== Technical Translation in Spanish ===\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "    Status: 500 Error interno del servidor\n",
       "    Response: {\n",
       "        'error': 'Fall la conexin a la base de datos',\n",
       "        'code': 'DB_001',\n",
       "        'timestamp': '2024-03-20T10:30:00Z'\n",
       "    }\n",
       "\n",
       "    Nota tcnica: Este error ocurre cuando la aplicacin no puede conectarse a la base de datos.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# Create the system message with examples\n",
    "system_message = SystemMessage(content=\"\"\"You are a technical translator. You must maintain the exact same format and structure in your translations.\n",
    "Only translate the explanatory text, keeping all technical terms, numbers, and formatting unchanged.\n",
    "\n",
    "Example input and output pairs:\n",
    "\n",
    "Input: \"Error 404: Page not found\"\n",
    "Output: \"Error 404: Pgina no encontrada\"\n",
    "\n",
    "Input: \"Status: 200 OK\n",
    "Response: {\n",
    "    'data': 'success',\n",
    "    'message': 'Operation completed'\n",
    "}\"\n",
    "Output: \"Status: 200 OK\n",
    "Response: {\n",
    "    'data': 'success',\n",
    "    'message': 'Operacin completada'\n",
    "}\"\n",
    "\"\"\")\n",
    "\n",
    "# Loop through each language\n",
    "for language in languages:\n",
    "    print_text(f\"\\n=== Technical Translation in {language} ===\")\n",
    "\n",
    "    # Create the human message using f-string\n",
    "    human_message = HumanMessage(content=f\"\"\"Translate this technical information to {language}:\n",
    "\n",
    "    Status: 500 Internal Server Error\n",
    "    Response: {{\n",
    "        'error': 'Database connection failed',\n",
    "        'code': 'DB_001',\n",
    "        'timestamp': '2024-03-20T10:30:00Z'\n",
    "    }}\n",
    "\n",
    "    Technical Note: This error occurs when the application cannot connect to the database.\n",
    "    \"\"\")\n",
    "\n",
    "    # Create messages list\n",
    "    messages = [system_message, human_message]\n",
    "\n",
    "    # Get response\n",
    "    res = chat_llm.invoke(messages)\n",
    "    time.sleep(3)\n",
    "\n",
    "    print_text(res.content)\n",
    "    print_text(\"=\" * 80)  # Separator for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af1a7cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "=== Technical Translation in English ===\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Status: 500 Internal Server Error\n",
       "Response: {{\n",
       "    'error': 'Database connection failed',\n",
       "    'code': 'DB_001',\n",
       "    'timestamp': '2024-03-20T10:30:00Z'\n",
       "}}\n",
       "\n",
       "Technical Note: This error occurs when the application cannot establish a connection to the database.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "=== Technical Translation in Esperanto ===\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Status: 500 Interna Servera Eraro\n",
       "Response: {{\n",
       "    'eraro': 'Fremetiga konekto al la datumaro malsukcesis',\n",
       "    'kodo': 'DB_001',\n",
       "    'tempo': '2024-03-20T10:30:00Z'\n",
       "}}\n",
       "\n",
       "Teknologia Noto: i tiu eraro okazas, kiam la aplikao ne sukcesas konektii al la datumaro.\n",
       "\n",
       "    \n",
       "    Noto: Bonvolu konservi formalan tonon en la traduko.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "=== Technical Translation in Spanish ===\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "    Estado: 500 Error interno del servidor\n",
       "    Respuesta: {{\n",
       "        'error': 'Fall la conexin con la base de datos',\n",
       "        'code': 'DB_001',\n",
       "        'timestamp': '2024-03-20T10:30:00Z'\n",
       "    }}\n",
       "\n",
       "    Nota tcnica: Este error se produce cuando la aplicacin no es capaz de conectarse con la base de datos.\n",
       "\n",
       "    \n",
       "    Observacin: Por favor, mantenga un tono formal en la traduccin.\n",
       "\n",
       "    \n",
       "    Se mantiene el trmino \"DB_001\" sin cambios en la traduccin.\n",
       "    \n",
       "    Se mantiene el trmino \"Internal Server Error\" sin cambios en la traduccin.\n",
       "    \n",
       "    Se mantiene el trmino \"Database connection\" sin cambios en la traduccin.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create few-shot examples for technical content formatting\n",
    "system_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are a technical translator. You must maintain the exact same format and structure in your translations.\n",
    "    Only translate the explanatory text, keeping all technical terms, numbers, and formatting unchanged.\n",
    "\n",
    "    Example input and output pairs:\n",
    "\n",
    "    Input: \"Error 404: Page not found\"\n",
    "    Output: \"Error 404: Pgina no encontrada\"\n",
    "\n",
    "    Input: \"Status: 200 OK\n",
    "    Response: {% raw %}{{\n",
    "        'data': 'success',\n",
    "        'message': 'Operation completed'\n",
    "    }}{% endraw %}\"\n",
    "    Output: \"Status: 200 OK\n",
    "    Response: {% raw %}{{\n",
    "        'data': 'success',\n",
    "        'message': 'Operacin completada'\n",
    "    }}{% endraw %}\"\n",
    "    \"\"\",\n",
    "    template_format=\"jinja2\"\n",
    ")\n",
    "\n",
    "# Example of a technical input using Jinja2's control structures and filters\n",
    "human_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"Translate this technical information to {{ language|upper }}:\n",
    "\n",
    "    Status: 500 Internal Server Error\n",
    "    Response: {% raw %}{{\n",
    "        'error': 'Database connection failed',\n",
    "        'code': 'DB_001',\n",
    "        'timestamp': '2024-03-20T10:30:00Z'\n",
    "    }}{% endraw %}\n",
    "\n",
    "    Technical Note: This error occurs when the application cannot connect to the database.\n",
    "\n",
    "    {% if language == 'spanish' %}\n",
    "    Note: Please use formal Spanish for technical documentation.\n",
    "    {% elif language == 'french' %}\n",
    "    Note: Please use formal French for technical documentation.\n",
    "    {% else %}\n",
    "    Note: Please maintain a formal tone in the translation.\n",
    "    {% endif %}\n",
    "\n",
    "    {% for term in technical_terms %}\n",
    "    Keep the term \"{{ term }}\" unchanged in the translation.\n",
    "    {% endfor %}\n",
    "    \"\"\",\n",
    "    template_format=\"jinja2\"\n",
    ")\n",
    "\n",
    "# Create the chain using LCEL pipe syntax\n",
    "chain = (\n",
    "    ChatPromptTemplate.from_messages([system_template, human_template])\n",
    "    | chat_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Loop through each language\n",
    "for language in languages:\n",
    "    print_text(f\"\\n=== Technical Translation in {language} ===\")\n",
    "\n",
    "    # Invoke the chain with our inputs\n",
    "    result = chain.invoke({\n",
    "        \"language\": language,\n",
    "        \"technical_terms\": ['DB_001', 'Internal Server Error', 'Database connection']\n",
    "    })\n",
    "    time.sleep(3)\n",
    "\n",
    "    print_text(result)\n",
    "    print_text(\"=\" * 80)  # Separator for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0ae5747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "=== Formatted Prompt for Spanish ===\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "SYSTEM MESSAGE:\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "----------------------------------------\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "You are a technical translator. You must maintain the exact same format and structure in your translations.\n",
       "    Only translate the explanatory text, keeping all technical terms, numbers, and formatting unchanged.\n",
       "\n",
       "    Example input and output pairs:\n",
       "\n",
       "    Input: \"Error 404: Page not found\"\n",
       "    Output: \"Error 404: Pgina no encontrada\"\n",
       "\n",
       "    Input: \"Status: 200 OK\n",
       "    Response: {{\n",
       "        'data': 'success',\n",
       "        'message': 'Operation completed'\n",
       "    }}\"\n",
       "    Output: \"Status: 200 OK\n",
       "    Response: {{\n",
       "        'data': 'success',\n",
       "        'message': 'Operacin completada'\n",
       "    }}\"\n",
       "    \n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "\n",
       "HUMAN MESSAGE:\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "----------------------------------------\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Translate this technical information to SPANISH:\n",
       "\n",
       "    Status: 500 Internal Server Error\n",
       "    Response: {{\n",
       "        'error': 'Database connection failed',\n",
       "        'code': 'DB_001',\n",
       "        'timestamp': '2024-03-20T10:30:00Z'\n",
       "    }}\n",
       "\n",
       "    Technical Note: This error occurs when the application cannot connect to the database.\n",
       "\n",
       "    \n",
       "    Note: Please use formal Spanish for technical documentation.\n",
       "    \n",
       "\n",
       "    \n",
       "    Keep the term \"DB_001\" unchanged in the translation.\n",
       "    \n",
       "    Keep the term \"Internal Server Error\" unchanged in the translation.\n",
       "    \n",
       "    Keep the term \"Database connection\" unchanged in the translation.\n",
       "    \n",
       "    \n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "================================================================================\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the formatted prompt for Spanish\n",
    "print_text(\"\\n=== Formatted Prompt for Spanish ===\")\n",
    "\n",
    "# Format the prompts with our inputs\n",
    "formatted_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_template,\n",
    "    human_template\n",
    "]).format_prompt(\n",
    "    language='spanish',\n",
    "    technical_terms=['DB_001', 'Internal Server Error', 'Database connection']\n",
    ")\n",
    "\n",
    "# Print the formatted messages\n",
    "for message in formatted_prompt.to_messages():\n",
    "    print_text(f\"\\n{message.type.upper()} MESSAGE:\")\n",
    "    print_text(\"-\" * 40)\n",
    "    print_text(message.content)\n",
    "    print_text(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa0be21",
   "metadata": {},
   "source": [
    "# Lanchain Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520f15d1",
   "metadata": {},
   "source": [
    "## Simple Chain example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6dd75cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "The result is: 2.4116004626599237\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a function to handle calculations\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Calculate using numexpr, with support for basic math operations.\"\"\"\n",
    "    try:\n",
    "        result = float(numexpr.evaluate(expression))\n",
    "        return f\"The result is: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {str(e)}\"\n",
    "\n",
    "# Create the prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful math assistant. When given a math problem, respond ONLY with the mathematical expression that would solve it. For example, if asked 'What is 2 raised to the 3rd power?', respond only with '2**3'.\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Wrap our calculation function with RunnableLambda for explicit LCEL pattern\n",
    "calculate_runnable = RunnableLambda(calculate)\n",
    "\n",
    "# Create the chain using LCEL with explicit RunnableLambda\n",
    "math_chain = (\n",
    "    prompt\n",
    "    | chat_llm  # LLM to generate the expression\n",
    "    | StrOutputParser()  # Convert to string\n",
    "    | calculate_runnable  # Our calculation function wrapped in RunnableLambda\n",
    ")\n",
    "\n",
    "# Use the chain with our example\n",
    "response = math_chain.invoke({\n",
    "    \"question\": \"What is 13 raised to the .3432 power?\"\n",
    "})\n",
    "time.sleep(3)\n",
    "print_text(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66b3e3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "To calculate 13 raised to the 0.3432 power, we need to use the concept of exponentiation. \n",
       "\n",
       "Exponentiation can be expressed as:\n",
       "\n",
       "a^b = a multiplied by itself b times\n",
       "\n",
       "However, in this case, we can also use the mathematical function exp(b * ln(a)), where ln(a) is the natural logarithm of a.\n",
       "\n",
       "Let's calculate the value:\n",
       "\n",
       "a = 13\n",
       "b = 0.3432\n",
       "\n",
       "First, we need to find the natural logarithm of 13:\n",
       "ln(13)  2.5649\n",
       "\n",
       "Now, we multiply b by ln(a):\n",
       "b * ln(a) = 0.3432 * 2.5649  0.8805\n",
       "\n",
       "Now, we apply the exponential function:\n",
       "exp(0.8805)  2.403\n",
       "\n",
       "So, 13 raised to the 0.3432 power is approximately 2.403.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple prompt without guidance\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "basic_chain = (\n",
    "    prompt\n",
    "    | chat_llm  # LLM tries to calculate directly\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = basic_chain.invoke({\n",
    "    \"question\": \"What is 13 raised to the .3432 power?\"\n",
    "})\n",
    "time.sleep(3)\n",
    "print_text(response)  # The LLM tries to calculate it directly and might get it wrong!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e3ce74",
   "metadata": {},
   "source": [
    "## Building Complex Chains with LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae189099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    # replace multiple new lines and multiple spaces with a single one\n",
    "    text = re.sub(r'(\\r\\n|\\r|\\n){2,}', r'\\n', text)\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0db304bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a creative writing assistant.\"),\n",
    "    (\"user\", \"\"\"Please paraphrase this text in the style of {style}: {text}\"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b988b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Yo, listen up, I got a tale to tell,\n",
       "'Bout chains, the tech that makes the magic swell,\n",
       "See, we got these components, multiple and strong,\n",
       "But solo, they're weak, they ain't where it belongs.\n",
       "\n",
       "But then we hit 'em with a chain, a link in the game,\n",
       "Now we got multiple components, all in the same frame,\n",
       "User input, formatted right, with a PromptTemplate tight,\n",
       " Pass it to an LLM, day and night, it's gettin' tight.\n",
       "\n",
       "We build the chain, we add some flair,\n",
       "More complex chains, we show we care,\n",
       "Combine 'em together, make 'em strong and new,\n",
       "Or mix 'em with other components, the possibilities are true.\n",
       "\n",
       "So when you're workin' with tech, and you need it to shine,\n",
       "Just remember chains, they'll make your app divine.\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the chain using LCEL\n",
    "style_chain = (\n",
    "    {\n",
    "        \"text\": lambda x: clean_text(x[\"text\"]),  # Extract and clean the text from input dict\n",
    "        \"style\": lambda x: x[\"style\"]  # Extract style from input dict\n",
    "    }\n",
    "    | prompt  # Format with our template\n",
    "    | chat_llm  # Generate creative paraphrase\n",
    "    | StrOutputParser()  # Convert to string\n",
    ")\n",
    "\n",
    "# Our input text with messy spacing\n",
    "input_text = \"\"\"\n",
    "Chains allow us to combine multiple\n",
    "\n",
    "\n",
    "components together to create a single, coherent application.\n",
    "\n",
    "For example, we can create a chain that takes user input,       format it with a PromptTemplate,\n",
    "\n",
    "and then passes the formatted response to an LLM. We can build more complex chains by combining     multiple chains together, or by\n",
    "\n",
    "\n",
    "combining chains with other components.\n",
    "\"\"\"\n",
    "\n",
    "# Run the chain\n",
    "response = style_chain.invoke({\n",
    "    \"text\": input_text,\n",
    "    \"style\": \"a 90s rapper\"\n",
    "})\n",
    "time.sleep(3)\n",
    "print_text(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d55040",
   "metadata": {},
   "source": [
    "## Using RunnableParallel and RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6d6e62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: The sentiment of the given statement is overwhelmingly **POSITIVE**.\n",
      "\n",
      "The words and phrases used convey a sense of satisfaction and delight:\n",
      "\n",
      "- \"exceeded my expectations\" implies that the product met or surpassed the user's high standards, which is a positive outcome.\n",
      "- \"Great quality\" is a subjective evaluation, but it's a common phrase used to express admiration and approval.\n",
      "\n",
      "The overall tone of the statement is enthusiastic and optimistic, indicating that the user is extremely pleased with the product.\n",
      "Summary: The product met or exceeded expectations due to its high quality.\n",
      "Original: The product exceeded my expectations. Great quality!\n"
     ]
    }
   ],
   "source": [
    "# Create two different analysis prompts\n",
    "sentiment_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a sentiment analysis expert. Analyze the emotional tone.\"),\n",
    "    (\"user\", \"What's the sentiment of: {text}\")\n",
    "])\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a summarization expert.\"),\n",
    "    (\"user\", \"Summarize in one sentence: {text}\")\n",
    "])\n",
    "\n",
    "# Use RunnableParallel to run both analyses simultaneously\n",
    "analysis_chain = RunnableParallel(\n",
    "    {\n",
    "        \"sentiment\": sentiment_prompt | chat_llm | StrOutputParser(),\n",
    "        \"summary\": summary_prompt | chat_llm | StrOutputParser(),\n",
    "        \"original\": RunnablePassthrough()  # Pass through the original input\n",
    "    }\n",
    ")\n",
    "\n",
    "# Test it\n",
    "sample_text = {\"text\": \"The product exceeded my expectations. Great quality!\"}\n",
    "results = analysis_chain.invoke(sample_text)\n",
    "time.sleep(3)\n",
    "\n",
    "print(\"Sentiment:\", results[\"sentiment\"])\n",
    "print(\"Summary:\", results[\"summary\"])\n",
    "print(\"Original:\", results[\"original\"][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e827b3",
   "metadata": {},
   "source": [
    "## Batch Processing with LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b6d9df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Q: What is the capital of France?\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "A: The capital of France is Paris.\n",
       "\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Q: Who wrote Romeo and Juliet?\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "A: Romeo and Juliet was written by William Shakespeare.\n",
       "\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "Q: What is the speed of light?\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size: 17px;\">\n",
       "\n",
       "A: The speed of light in a vacuum is approximately 299,792 kilometers per second (km/s) or about 186,282 miles per second (mi/s).\n",
       "\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a simple question-answering chain\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer concisely.\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "qa_chain = qa_prompt | chat_llm | StrOutputParser()\n",
    "\n",
    "# Batch of questions\n",
    "questions = [\n",
    "    {\"question\": \"What is the capital of France?\"},\n",
    "    {\"question\": \"Who wrote Romeo and Juliet?\"},\n",
    "    {\"question\": \"What is the speed of light?\"}\n",
    "]\n",
    "\n",
    "# Process all questions in batch\n",
    "answers = qa_chain.batch(questions)\n",
    "time.sleep(3)\n",
    "\n",
    "# Display results\n",
    "for q, a in zip(questions, answers):\n",
    "    print_text(f\"Q: {q['question']}\")\n",
    "    print_text(f\"A: {a}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}