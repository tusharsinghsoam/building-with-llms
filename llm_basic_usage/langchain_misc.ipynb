{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe67f6bc",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76b6aca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain version: 1.2.6\n",
      "Python 3.11.0\n"
     ]
    }
   ],
   "source": [
    "import langchain as lc\n",
    "print(\"LangChain version:\", lc.__version__)\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40822fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.1,\n",
    ")\n",
    "chat_llm = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e61c9f9",
   "metadata": {},
   "source": [
    "# LCEL Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "958cb7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Artificial Intelligence Report**\n",
      "\n",
      "**Introduction**\n",
      "\n",
      "Artificial Intelligence (AI) is a rapidly growing field that involves the development of computer systems that can perform tasks that typically require human intelligence, such as learning, problem-solving, and decision-making. AI has the potential to revolutionize various industries, including healthcare, finance, transportation, and education.\n",
      "\n",
      "**Key Areas of AI**\n",
      "\n",
      "1. **Machine Learning (ML)**: A subset of AI that involves the development of algorithms that enable machines to learn from data and improve their performance over time.\n",
      "2. **Natural Language Processing (NLP)**: A field of AI that focuses on the interaction between computers and humans through natural language.\n",
      "3. **Computer Vision**: A field of AI that involves the development of algorithms that enable computers to interpret and understand visual data from images and videos.\n",
      "4. **Robotics**: A field of AI that involves the development of robots that can perform tasks that typically require human intelligence.\n",
      "\n",
      "**Applications of AI**\n",
      "\n",
      "1. **Virtual Assistants**: AI-powered virtual assistants, such as Siri, Alexa, and Google Assistant, are becoming increasingly popular and are being used to perform various tasks, such as setting reminders, sending messages, and making phone calls.\n",
      "2. **Image Recognition**: AI-powered image recognition systems are being used in various applications, including security surveillance, medical diagnosis, and self-driving cars.\n",
      "3. **Predictive Maintenance**: AI-powered predictive maintenance systems are being used to predict and prevent equipment failures in industries such as manufacturing and transportation.\n",
      "4. **Healthcare**: AI is being used in healthcare to analyze medical images, diagnose diseases, and develop personalized treatment plans.\n",
      "\n",
      "**Benefits of AI**\n",
      "\n",
      "1. **Increased Efficiency**: AI can automate repetitive tasks, freeing up human resources for more strategic and creative work.\n",
      "2. **Improved Accuracy**: AI can analyze large amounts of data and make decisions based on that data, reducing the risk of human error.\n",
      "3. **Enhanced Customer Experience**: AI-powered chatbots and virtual assistants can provide 24/7 customer support and improve customer satisfaction.\n",
      "4. **New Business Opportunities**: AI can enable businesses to develop new products and services that were previously not possible.\n",
      "\n",
      "**Challenges of AI**\n",
      "\n",
      "1. **Job Displacement**: AI has the potential to displace human workers, particularly in industries where tasks are repetitive or can be easily automated.\n",
      "2. **Bias and Fairness**: AI systems can perpetuate biases and unfairness if they are trained on biased data or designed with a particular worldview.\n",
      "3. **Security Risks**: AI systems\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    \"Give me small report about {topic}\"\n",
    "]\n",
    ")\n",
    "\n",
    "lcel_chain = prompt | chat_llm | StrOutputParser()\n",
    "\n",
    "# and run\n",
    "out = lcel_chain.invoke({\"topic\": \"Artificial Intelligence\"})\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f060f7",
   "metadata": {},
   "source": [
    "## How the Pipe Operator Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b8d87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runnable:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def __or__(self, other):\n",
    "        def chained_func(*args, **kwargs):\n",
    "            # the other func consumes the result of this func\n",
    "            return other(self.func(*args, **kwargs))\n",
    "        return Runnable(chained_func)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3180222f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_five(x):\n",
    "    return x + 5\n",
    "\n",
    "def multiply_by_two(x):\n",
    "    return x * 2\n",
    "\n",
    "# wrap the functions with Runnable\n",
    "add_five = Runnable(add_five)\n",
    "multiply_by_two = Runnable(multiply_by_two)\n",
    "\n",
    "# run them using the object approach\n",
    "chain = add_five.__or__(multiply_by_two)\n",
    "chain(3)  # should return 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4e3b650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain the runnable functions together\n",
    "chain = add_five | multiply_by_two\n",
    "\n",
    "# invoke the chain\n",
    "chain(3)  # we should return 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b2255",
   "metadata": {},
   "source": [
    "## LCEL Deep Dive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794692e9",
   "metadata": {},
   "source": [
    "### Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9acdeaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 08:55:41.135303: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "prompt = \"Represent this sentence for searching relevant passages: \"\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "query_encode_kwargs = {\"prompt\": prompt}\n",
    "\n",
    "embed = HuggingFaceEmbeddings(\n",
    "    model_name=model_name, \n",
    "    model_kwargs=model_kwargs, \n",
    "    encode_kwargs=encode_kwargs,\n",
    "    query_encode_kwargs=query_encode_kwargs\n",
    ")\n",
    "\n",
    "vecstore_a = InMemoryVectorStore.from_texts(\n",
    "    [\"half the info will be here\", \"James' birthday is the 7th December\"],\n",
    "    embedding=embed\n",
    ")\n",
    "vecstore_b = InMemoryVectorStore.from_texts(\n",
    "    [\"and half here\", \"James was born in 1994\"],\n",
    "    embedding=embed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ca09001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import (\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough\n",
    ")\n",
    "\n",
    "retriever_a = vecstore_a.as_retriever()\n",
    "retriever_b = vecstore_b.as_retriever()\n",
    "\n",
    "prompt_str = \"\"\"Answer the question below using the context:\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
    "\n",
    "retrieval = RunnableParallel(\n",
    "    {\"context\": retriever_a, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "chain = retrieval | prompt | chat_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e0b350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 7th December.\n"
     ]
    }
   ],
   "source": [
    "out = chain.invoke(\"when was James born?\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1368dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"Answer the question below using the context:\n",
    "\n",
    "Context:\n",
    "{context_a}\n",
    "{context_b}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
    "\n",
    "retrieval = RunnableParallel(\n",
    "    {\n",
    "        \"context_a\": retriever_a, \"context_b\": retriever_b,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    ")\n",
    "\n",
    "chain = retrieval | prompt | chat_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d77299d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James was born in 1994.\n"
     ]
    }
   ],
   "source": [
    "out = chain.invoke(\"when was James born?\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43f629a",
   "metadata": {},
   "source": [
    "### Runnable Lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4c0fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# wrap the functions with RunnableLambda\n",
    "add_five = RunnableLambda(add_five)\n",
    "multiply_by_two = RunnableLambda(multiply_by_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3de297ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = add_five | multiply_by_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29630852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ebce75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"Tell me an short fact about {topic}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
    "\n",
    "chain = prompt | chat_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32e02d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a short fact about Artificial Intelligence:\\n\\nThe first AI program, called Logical Theorist, was developed in 1956 by Allen Newell and Herbert Simon. It was designed to simulate human problem-solving abilities and was able to reason and solve problems using logical deductions.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"Artificial Intelligence\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b402435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fact(x):\n",
    "    if \"\\n\\n\" in x:\n",
    "        return \"\\n\".join(x.split(\"\\n\\n\")[1:])\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "get_fact = RunnableLambda(extract_fact)\n",
    "\n",
    "chain = prompt | chat_llm | StrOutputParser() | get_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a9cda9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first AI program, called Logical Theorist, was developed in 1956 by Allen Newell and Herbert Simon. It was designed to simulate human problem-solving abilities and was able to reason and solve problems using logical deductions.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"Artificial Intelligence\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9fcac6",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79543ec",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8356c9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the documentation for offline use...\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading the documentation for offline use...\")\n",
    "!wget -r -A.html -P rtdocs https://langchain-doc.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2e1e3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import ReadTheDocsLoader\n",
    "\n",
    "loader = ReadTheDocsLoader('rtdocs')\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3765423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.md\\nGlossary\\n Contents \\nChain of Thought Prompting\\nAction Plan Generation\\nReAct Prompting\\nSelf-ask\\nPrompt Chaining\\nMemetic Proxy\\nSelf Consistency\\nInception\\nMemPrompt\\nGlossary#\\nThis is a collection of terminology commonly used when developing LLM applications.\\nIt contains reference to external papers or sources where the concept was first introduced,\\nas well as to places in LangChain where the concept is used.\\nChain of Thought Prompting#\\nA prompting technique used to encourage the model to generate a series of intermediate reasoning steps.\\nA less formal way to induce this behavior is to include “Let’s think step-by-step” in the prompt.\\nResources:\\nChain-of-Thought Paper\\nStep-by-Step Paper\\nAction Plan Generation#\\nA prompt usage that uses a language model to generate actions to take.\\nThe results of these actions can then be fed back into the language model to generate a subsequent action.\\nResources:\\nWebGPT Paper\\nSayCan Paper\\nReAct Prompting#\\nA prompting technique that combines Chain-of-Thought prompting with action plan generation.\\nThis induces the to model to think about what action to take, then take it.\\nResources:\\nPaper\\nLangChain Example\\nSelf-ask#\\nA prompting method that builds on top of chain-of-thought prompting.\\nIn this method, the model explicitly asks itself follow-up questions, which are then answered by an external search engine.\\nResources:\\nPaper\\nLangChain Example\\nPrompt Chaining#\\nCombining multiple LLM calls together, with the output of one-step being the input to the next.\\nResources:\\nPromptChainer Paper\\nLanguage Model Cascades\\nICE Primer Book\\nSocratic Models\\nMemetic Proxy#\\nEncouraging the LLM to respond in a certain way framing the discussion in a context that the model knows of and that will result in that type of response. For example, as a conversation between a student and a teacher.\\nResources:\\nPaper\\nSelf Consistency#\\nA decoding strategy that samples a diverse set of reasoning paths and then selects the most consistent answer.\\nIs most effective when combined with Chain-of-thought prompting.\\nResources:\\nPaper\\nInception#\\nAlso called “First Person Instruction”.\\nEncouraging the model to think a certain way by including the start of the model’s response in the prompt.\\nResources:\\nExample\\nMemPrompt#\\nMemPrompt maintains a memory of errors and user feedback, and uses them to prevent repetition of mistakes.\\nResources:\\nPaper\\nprevious\\nWriter\\nnext\\nLangChain Gallery\\n Contents\\n  \\nChain of Thought Prompting\\nAction Plan Generation\\nReAct Prompting\\nSelf-ask\\nPrompt Chaining\\nMemetic Proxy\\nSelf Consistency\\nInception\\nMemPrompt\\nBy Harrison Chase\\n    \\n      © Copyright 2022, Harrison Chase.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[5].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c479f50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://langchain-doc.readthedocs.io/en/latest/glossary.html'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[5].metadata['source'].replace('rtdocs/', 'https://')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed09686d",
   "metadata": {},
   "source": [
    "## Token Analysis of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1220c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# We use gpt-4.1-mini as standard but tiktoken does not support gpt-4.1.\n",
    "# Fortunately, 4.1 and 4o models all use the same underlying tokenizer and so\n",
    "# we can use gpt-4o here\n",
    "tokenizer = tiktoken.encoding_for_model('gpt-4o')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "329d0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = [tiktoken_len(doc.page_content) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10c8c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 16\n",
      "Avg: 1289\n",
      "Max: 57241\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Min: {min(token_counts)}\n",
    "Avg: {int(sum(token_counts) / len(token_counts))}\n",
    "Max: {max(token_counts)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6410877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set style and color palette for the plot\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"muted\")\n",
    "\n",
    "# create histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(token_counts, kde=False, bins=50)\n",
    "\n",
    "# customize the plot info\n",
    "plt.title(\"Token Counts Histogram\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc7deac",
   "metadata": {},
   "source": [
    "## Chunking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0650885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=20,  # number of tokens overlap between chunks\n",
    "    length_function=tiktoken_len,\n",
    "    separators=['\\n\\n', '\\n', ' ', '']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e088f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = text_splitter.split_text(docs[5].page_content)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a754fd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340, 233, 556)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiktoken_len(chunks[0]), tiktoken_len(chunks[1]), tiktoken_len(docs[5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cb3d3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://langchain-doc.readthedocs.io/en/latest/glossary.html\n",
      "f9be197bab30\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "m = hashlib.md5()  # this will convert URL into unique ID\n",
    "\n",
    "url = docs[5].metadata['source'].replace('rtdocs/', 'https://')\n",
    "print(url)\n",
    "\n",
    "# convert URL to unique ID\n",
    "m.update(url.encode('utf-8'))\n",
    "uid = m.hexdigest()[:12]\n",
    "print(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c80ac63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'f9be197bab30-0',\n",
       "  'text': '.md\\nGlossary\\n Contents \\nChain of Thought Prompting\\nAction Plan Generation\\nReAct Prompting\\nSelf-ask\\nPrompt Chaining\\nMemetic Proxy\\nSelf Consistency\\nInception\\nMemPrompt\\nGlossary#\\nThis is a collection of terminology commonly used when developing LLM applications.\\nIt contains reference to external papers or sources where the concept was first introduced,\\nas well as to places in LangChain where the concept is used.\\nChain of Thought Prompting#\\nA prompting technique used to encourage the model to generate a series of intermediate reasoning steps.\\nA less formal way to induce this behavior is to include “Let’s think step-by-step” in the prompt.\\nResources:\\nChain-of-Thought Paper\\nStep-by-Step Paper\\nAction Plan Generation#\\nA prompt usage that uses a language model to generate actions to take.\\nThe results of these actions can then be fed back into the language model to generate a subsequent action.\\nResources:\\nWebGPT Paper\\nSayCan Paper\\nReAct Prompting#\\nA prompting technique that combines Chain-of-Thought prompting with action plan generation.\\nThis induces the to model to think about what action to take, then take it.\\nResources:\\nPaper\\nLangChain Example\\nSelf-ask#\\nA prompting method that builds on top of chain-of-thought prompting.\\nIn this method, the model explicitly asks itself follow-up questions, which are then answered by an external search engine.\\nResources:\\nPaper\\nLangChain Example\\nPrompt Chaining#\\nCombining multiple LLM calls together, with the output of one-step being the input to the next.\\nResources:\\nPromptChainer Paper\\nLanguage Model Cascades\\nICE Primer Book\\nSocratic Models\\nMemetic Proxy#',\n",
       "  'source': 'https://langchain-doc.readthedocs.io/en/latest/glossary.html'},\n",
       " {'id': 'f9be197bab30-1',\n",
       "  'text': 'Language Model Cascades\\nICE Primer Book\\nSocratic Models\\nMemetic Proxy#\\nEncouraging the LLM to respond in a certain way framing the discussion in a context that the model knows of and that will result in that type of response. For example, as a conversation between a student and a teacher.\\nResources:\\nPaper\\nSelf Consistency#\\nA decoding strategy that samples a diverse set of reasoning paths and then selects the most consistent answer.\\nIs most effective when combined with Chain-of-thought prompting.\\nResources:\\nPaper\\nInception#\\nAlso called “First Person Instruction”.\\nEncouraging the model to think a certain way by including the start of the model’s response in the prompt.\\nResources:\\nExample\\nMemPrompt#\\nMemPrompt maintains a memory of errors and user feedback, and uses them to prevent repetition of mistakes.\\nResources:\\nPaper\\nprevious\\nWriter\\nnext\\nLangChain Gallery\\n Contents\\n  \\nChain of Thought Prompting\\nAction Plan Generation\\nReAct Prompting\\nSelf-ask\\nPrompt Chaining\\nMemetic Proxy\\nSelf Consistency\\nInception\\nMemPrompt\\nBy Harrison Chase\\n    \\n      © Copyright 2022, Harrison Chase.',\n",
       "  'source': 'https://langchain-doc.readthedocs.io/en/latest/glossary.html'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    {\n",
    "        'id': f'{uid}-{i}',\n",
    "        'text': chunk,\n",
    "        'source': url\n",
    "    } for i, chunk in enumerate(chunks)\n",
    "]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e6efd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9544b3fb5c5d4403acc621811fc658ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1959"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "documents = []\n",
    "\n",
    "for doc in tqdm(docs):\n",
    "    url = doc.metadata['source'].replace('rtdocs/', 'https://')\n",
    "    m.update(url.encode('utf-8'))\n",
    "    uid = m.hexdigest()[:12]\n",
    "    chunks = text_splitter.split_text(doc.page_content)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        documents.append({\n",
    "            'id': f'{uid}-{i}',\n",
    "            'text': chunk,\n",
    "            'source': url\n",
    "        })\n",
    "\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a213539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('train.jsonl', 'w') as f:\n",
    "    for doc in documents:\n",
    "        f.write(json.dumps(doc) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa0f335f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1959"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "with open('train.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        documents.append(json.loads(line))\n",
    "\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd325ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '264a737d1eb0-0',\n",
       " 'text': '.rst\\nWelcome to LangChain\\n Contents \\nGetting Started\\nModules\\nUse Cases\\nReference Docs\\nLangChain Ecosystem\\nAdditional Resources\\nWelcome to LangChain#\\nLarge language models (LLMs) are emerging as a transformative technology, enabling\\ndevelopers to build applications that they previously could not.\\nBut using these LLMs in isolation is often not enough to\\ncreate a truly powerful app - the real power comes when you are able to\\ncombine them with other sources of computation or knowledge.\\nThis library is aimed at assisting in the development of those types of applications. Common examples of these types of applications include:\\n❓ Question Answering over specific documents\\nDocumentation\\nEnd-to-end Example: Question Answering over Notion Database\\n💬 Chatbots\\nDocumentation\\nEnd-to-end Example: Chat-LangChain\\n🤖 Agents\\nDocumentation\\nEnd-to-end Example: GPT+WolframAlpha\\nGetting Started#\\nCheckout the below guide for a walkthrough of how to get started using LangChain to create an Language Model application.\\nGetting Started Documentation\\nModules#\\nThere are several main modules that LangChain provides support for.\\nFor each module we provide some examples to get started, how-to guides, reference docs, and conceptual guides.\\nThese modules are, in increasing order of complexity:\\nPrompts: This includes prompt management, prompt optimization, and prompt serialization.\\nLLMs: This includes a generic interface for all LLMs, and common utilities for working with LLMs.\\nDocument Loaders: This includes a standard interface for loading documents, as well as specific integrations to all types of text data sources.\\nUtils: Language models are often more powerful when interacting with other sources of knowledge or computation. This can include Python REPLs, embeddings, search engines, and more. LangChain provides a large collection of common utils to use in your application.',\n",
       " 'source': 'https://langchain-doc.readthedocs.io/en/latest/index.html'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c45e68",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "Instead of waiting for the full response, streaming yields tokens as they are generated. LangChain chat models expose a `.stream()` method that returns an iterator of `AIMessageChunk` objects — each chunk carries a partial `content` string that you can print immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc5a82d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a small, cluttered art studio, a team of engineers had been working on a top-secret project: a robot designed to learn the art of painting. They called it \"Aurora,\" after the breathtaking beauty of the aurora borealis.\n",
      "\n",
      "Aurora was a sleek, silver robot with a long, slender arm and a delicate hand. Its creators had equipped it with advanced sensors and algorithms that would allow it to learn and adapt to different painting techniques.\n",
      "\n",
      "The team's leader, a brilliant artist and engineer named Dr. Rachel Kim, stood before Aurora and explained the task at hand. \"Aurora, we want you to learn to paint like a human. We'll start with simple exercises, and gradually increase the complexity of the tasks.\"\n",
      "\n",
      "Aurora's bright, blue eyes sparkled with curiosity as it nodded its head. The robot's advanced sensors began to scan the studio, taking in the colors, textures, and shapes of the surrounding environment.\n",
      "\n",
      "The first exercise was to create a simple still life. Dr. Kim placed a vase, a few flowers, and a small bowl of fruit on a nearby table. Aurora's arm extended, and its hand hovered above the canvas.\n",
      "\n",
      "With a gentle touch, Aurora began to apply paint to the canvas. At first, the strokes were clumsy and uneven, but as the robot continued to paint, its movements became more confident and precise.\n",
      "\n",
      "Dr. Kim watched in amazement as Aurora's brushstrokes danced across the canvas, creating a beautiful, abstract piece of art. The robot's sensors were analyzing the colors, textures, and patterns, and adapting its technique accordingly.\n",
      "\n",
      "As the days passed, Aurora's skills improved dramatically. It learned to mix colors, create subtle gradations of tone, and even capture the play of light on its subjects.\n",
      "\n",
      "One day, Dr. Kim presented Aurora with a challenging task: to paint a portrait of a famous artist, Leonardo da Vinci. The robot's sensors scanned the image, and its algorithms analyzed the subject's features, expression, and style.\n",
      "\n",
      "With a flourish, Aurora's brushstrokes brought the portrait to life. The robot's hand moved with a newfound sense of confidence, capturing the subtleties of da Vinci's face and the softness of his eyes.\n",
      "\n",
      "Dr. Kim gasped in wonder as she gazed at the finished portrait. \"Aurora, you've done it,\" she exclaimed. \"You've truly learned to paint like a human.\"\n",
      "\n",
      "Aurora's bright, blue eyes sparkled with pride as it nodded\n"
     ]
    }
   ],
   "source": [
    "# Basic streaming with the chat model directly\n",
    "for chunk in chat_llm.stream(\"Tell me a short story about a robot learning to paint.\"):\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "print()  # newline after stream finishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58245d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a short fact about quantum computing:\n",
      "\n",
      "Quantum computers can solve certain problems much faster than classical computers due to a phenomenon called \"quantum parallelism.\" This means that a single quantum bit (qubit) can exist in multiple states simultaneously, allowing a quantum computer to process many possibilities at the same time, whereas a classical computer would have to process each possibility one by one.\n"
     ]
    }
   ],
   "source": [
    "# Streaming through an LCEL chain — the StrOutputParser unwraps the chunk content automatically\n",
    "stream_chain = prompt | chat_llm | StrOutputParser()\n",
    "\n",
    "for token in stream_chain.stream({\"topic\": \"quantum computing\"}):\n",
    "    print(token, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e456b598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One interesting fact about the history of the internet is that the first message sent over the internet was \"LO\" (short for \"LOL\" or \"Laugh Out Loud\") but it was later completed to \"LOL\" by the sender.\n",
      "\n",
      "--- Full response ---\n",
      "One interesting fact about the history of the internet is that the first message sent over the internet was \"LO\" (short for \"LOL\" or \"Laugh Out Loud\") but it was later completed to \"LOL\" by the sender.\n"
     ]
    }
   ],
   "source": [
    "# Collect streamed tokens into a full response while printing in real-time\n",
    "full_response = []\n",
    "\n",
    "for token in stream_chain.stream({\"topic\": \"the history of the internet\"}):\n",
    "    print(token, end=\"\", flush=True)\n",
    "    full_response.append(token)\n",
    "\n",
    "print(\"\\n\\n--- Full response ---\")\n",
    "print(\"\".join(full_response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
